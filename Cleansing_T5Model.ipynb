{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjmAE1eRHpcB"
      },
      "outputs": [],
      "source": [
        "# Install Hugging Face Transformers and ROUGE\n",
        "!pip install transformers datasets rouge-score -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "XDJfdwgOGhMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "M21vkDZ1Hyo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "ZpvZo1UOGkud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U57MS-aCIG-O",
        "outputId": "0f7d40fe-7db5-42c4-e5fc-39ad32c89c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_json(\"/content/drive/MyDrive/Binus/Sem 5/textmining/train.jsonl\", lines=True)\n",
        "# dfval = pd.read_json(\"/content/drive/MyDrive/Binus/Sem 5/textmining/dev.jsonl\", lines=True)\n",
        "# dftest = pd.read_json(\"/content/drive/MyDrive/Binus/Sem 5/textmining/test.jsonl\", lines=True)\n",
        "\n",
        "df = pd.read_json(\"/content/drive/MyDrive/sem 5/train.jsonl\", lines=True)\n",
        "dfval = pd.read_json(\"/content/drive/MyDrive/sem 5/dev.jsonl\", lines=True)\n",
        "dftest = pd.read_json(\"/content/drive/MyDrive/sem 5/test.jsonl\", lines=True)"
      ],
      "metadata": {
        "id": "mM7blMQ6ITTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "ngufvrDsITvm",
        "outputId": "99e6643d-044b-451d-9596-49d4b5260447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Due to the success of deep learning to solvin...   \n",
              "1  [The backpropagation (BP) algorithm is often t...   \n",
              "2  [We introduce the 2-simplicial Transformer, an...   \n",
              "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
              "4  [Recent efforts on combining deep models with ...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.30188678746885, 0.37209301838831804, 0.6037...   SysEexbRb   \n",
              "1  [0.0, 0.0, 0.130434779206049, 0.14285713922902...  SygvZ209F7   \n",
              "2  [0.333333328395061, 0.8888888839111111, 0.1142...  rkecJ6VFvr   \n",
              "3  [0.066666662222222, 0.06451612466181, 0.060606...   HJJ0w--0W   \n",
              "4  [0.27777777279320903, 0.571428566658163, 0.095...   HyH9lbZAW   \n",
              "\n",
              "                                              target    ic  \\\n",
              "0  [We provide necessary and sufficient analytica...  True   \n",
              "1  [Biologically plausible learning algorithms, p...  True   \n",
              "2  [We introduce the 2-simplicial Transformer and...  True   \n",
              "3  [Accurate forecasting over very long time hori...  True   \n",
              "4  [We propose a variational message-passing algo...  True   \n",
              "\n",
              "                                               title  \n",
              "0  Critical Points of Linear Neural Networks: Ana...  \n",
              "1  Biologically-Plausible Learning Algorithms Can...  \n",
              "2             Logic and the 2-Simplicial Transformer  \n",
              "3      Long-term Forecasting using Tensor-Train RNNs  \n",
              "4  Variational Message Passing with Structured In...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c390ab3e-38a3-4d06-8de5-66d009b5ffd1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>ic</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Due to the success of deep learning to solvin...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.30188678746885, 0.37209301838831804, 0.6037...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>[We provide necessary and sufficient analytica...</td>\n",
              "      <td>True</td>\n",
              "      <td>Critical Points of Linear Neural Networks: Ana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.130434779206049, 0.14285713922902...</td>\n",
              "      <td>SygvZ209F7</td>\n",
              "      <td>[Biologically plausible learning algorithms, p...</td>\n",
              "      <td>True</td>\n",
              "      <td>Biologically-Plausible Learning Algorithms Can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.333333328395061, 0.8888888839111111, 0.1142...</td>\n",
              "      <td>rkecJ6VFvr</td>\n",
              "      <td>[We introduce the 2-simplicial Transformer and...</td>\n",
              "      <td>True</td>\n",
              "      <td>Logic and the 2-Simplicial Transformer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.066666662222222, 0.06451612466181, 0.060606...</td>\n",
              "      <td>HJJ0w--0W</td>\n",
              "      <td>[Accurate forecasting over very long time hori...</td>\n",
              "      <td>True</td>\n",
              "      <td>Long-term Forecasting using Tensor-Train RNNs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Recent efforts on combining deep models with ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.27777777279320903, 0.571428566658163, 0.095...</td>\n",
              "      <td>HyH9lbZAW</td>\n",
              "      <td>[We propose a variational message-passing algo...</td>\n",
              "      <td>True</td>\n",
              "      <td>Variational Message Passing with Structured In...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c390ab3e-38a3-4d06-8de5-66d009b5ffd1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c390ab3e-38a3-4d06-8de5-66d009b5ffd1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c390ab3e-38a3-4d06-8de5-66d009b5ffd1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3aa9303d-d5de-4286-8e47-eeed181b23a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3aa9303d-d5de-4286-8e47-eeed181b23a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3aa9303d-d5de-4286-8e47-eeed181b23a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1992,\n        \"samples\": [\n          \"S1TgE7WR-\",\n          \"B1EiIsCctm\",\n          \"rknt2Be0-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1983,\n        \"samples\": [\n          \"Unsupervised Distillation of Syntactic Information from Contextualized Word Representations\",\n          \"Bridging ELBO objective and MMD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "azbagqCsKZah",
        "outputId": "a6527e2a-9974-4e8d-cd60-3cbda21b12a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Mixed precision training (MPT) is becoming a ...   \n",
              "1  [Many real-world problems, e.g. object detecti...   \n",
              "2  [Foveation is an important part of human visio...   \n",
              "3  [We explore the concept of co-design in the co...   \n",
              "4  [Batch Normalization (BatchNorm) has shown to ...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2                                    [0, 0, 1, 0, 0]   \n",
              "3  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.23999999580000003, 0.260869560822306, 0.199...  rJlnfaNYvB   \n",
              "1  [0.054054049086925, 0.29268292183224204, 0.974...  rJVoEiCqKQ   \n",
              "2  [0.11764705382352901, 0.11764705382352901, 0.3...  rkldVXKU8H   \n",
              "3  [0.12499999548828102, 0.488888883911111, 0.204...  BJfIVjAcKm   \n",
              "4  [0.1999999952, 0.239999995008, 0.3999999950080...  BJlEEaEFDS   \n",
              "\n",
              "                                              target     ic  \\\n",
              "0  [We devise adaptive loss scaling to improve mi...   True   \n",
              "1  [We present a novel approach for learning to p...   True   \n",
              "2  [We compare object recognition performance on ...  False   \n",
              "3  [We develop methods to train deep neural model...   True   \n",
              "4  [Investigation of how BatchNorm causes adversa...   True   \n",
              "\n",
              "                                               title  \n",
              "0  Adaptive Loss Scaling for Mixed Precision Trai...  \n",
              "1  Deep Perm-Set Net: Learn to predict sets with ...  \n",
              "2                   Foveated Downsampling Techniques  \n",
              "3  Training for Faster Adversarial Robustness Ver...  \n",
              "4  Towards an Adversarially Robust Normalization ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-132feaa0-b542-42da-b26e-46702435154f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>ic</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Mixed precision training (MPT) is becoming a ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.23999999580000003, 0.260869560822306, 0.199...</td>\n",
              "      <td>rJlnfaNYvB</td>\n",
              "      <td>[We devise adaptive loss scaling to improve mi...</td>\n",
              "      <td>True</td>\n",
              "      <td>Adaptive Loss Scaling for Mixed Precision Trai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Many real-world problems, e.g. object detecti...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.054054049086925, 0.29268292183224204, 0.974...</td>\n",
              "      <td>rJVoEiCqKQ</td>\n",
              "      <td>[We present a novel approach for learning to p...</td>\n",
              "      <td>True</td>\n",
              "      <td>Deep Perm-Set Net: Learn to predict sets with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Foveation is an important part of human visio...</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.11764705382352901, 0.11764705382352901, 0.3...</td>\n",
              "      <td>rkldVXKU8H</td>\n",
              "      <td>[We compare object recognition performance on ...</td>\n",
              "      <td>False</td>\n",
              "      <td>Foveated Downsampling Techniques</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We explore the concept of co-design in the co...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.12499999548828102, 0.488888883911111, 0.204...</td>\n",
              "      <td>BJfIVjAcKm</td>\n",
              "      <td>[We develop methods to train deep neural model...</td>\n",
              "      <td>True</td>\n",
              "      <td>Training for Faster Adversarial Robustness Ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Batch Normalization (BatchNorm) has shown to ...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.1999999952, 0.239999995008, 0.3999999950080...</td>\n",
              "      <td>BJlEEaEFDS</td>\n",
              "      <td>[Investigation of how BatchNorm causes adversa...</td>\n",
              "      <td>True</td>\n",
              "      <td>Towards an Adversarially Robust Normalization ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-132feaa0-b542-42da-b26e-46702435154f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-132feaa0-b542-42da-b26e-46702435154f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-132feaa0-b542-42da-b26e-46702435154f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f4f113de-a87c-4420-b973-9b7bb9e344bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4f113de-a87c-4420-b973-9b7bb9e344bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f4f113de-a87c-4420-b973-9b7bb9e344bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfval",
              "summary": "{\n  \"name\": \"dfval\",\n  \"rows\": 619,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 619,\n        \"samples\": [\n          \"S1xD6xHKDr\",\n          \"S1l-C0NtwS\",\n          \"HJxEhREKDH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 616,\n        \"samples\": [\n          \"Efficient Inference Amortization in Graphical Models using Structured Continuous Conditional Normalizing Flows\",\n          \"Improving One-Shot NAS By Suppressing The Posterior Fading\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "WuF3D6_QKsCz",
        "outputId": "0495bb88-998b-4498-9355-ba85e17828d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Incremental class learning involves sequentia...   \n",
              "1  [Multi-view learning can provide self-supervis...   \n",
              "2  [We show how discrete objects can be learnt in...   \n",
              "3  [Most recent gains in visual recognition have ...   \n",
              "4  [In recent years, deep neural networks have de...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
              "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.28571428104489804, 0.18181817681818102, 0.2...   SJ1Xmf-Rb   \n",
              "1  [0.19999999580000002, 0.0, 0.15789473418282501...  S1xzyhR9Y7   \n",
              "2  [0.9787233992575821, 0.33333332860555503, 0.41...   HJDUjKeA-   \n",
              "3  [0.11764705384083, 0.146341458655562, 0.199999...  BJgLg3R9KQ   \n",
              "4  [0.0, 0.05882352484429101, 0.270270265887509, ...  BklpOo09tQ   \n",
              "\n",
              "                                              target    ic  \\\n",
              "0  [FearNet is a memory efficient neural-network,...  True   \n",
              "1  [Multi-view learning improves unsupervised sen...  True   \n",
              "2  [We show how discrete objects can be learnt in...  True   \n",
              "3  [A large-scale dataset for training attention ...  True   \n",
              "4  [We proposed a time-efficient defense method a...  True   \n",
              "\n",
              "                                               title  \n",
              "0  FearNet: Brain-Inspired Model for Incremental ...  \n",
              "1  Improving Sentence Representations with Multi-...  \n",
              "2                       Learning objects from pixels  \n",
              "3                  Learning what and where to attend  \n",
              "4  EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEE...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7911446c-75d4-4cf5-a01a-a7e619e5f13e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>ic</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Incremental class learning involves sequentia...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.28571428104489804, 0.18181817681818102, 0.2...</td>\n",
              "      <td>SJ1Xmf-Rb</td>\n",
              "      <td>[FearNet is a memory efficient neural-network,...</td>\n",
              "      <td>True</td>\n",
              "      <td>FearNet: Brain-Inspired Model for Incremental ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Multi-view learning can provide self-supervis...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "      <td>[0.19999999580000002, 0.0, 0.15789473418282501...</td>\n",
              "      <td>S1xzyhR9Y7</td>\n",
              "      <td>[Multi-view learning improves unsupervised sen...</td>\n",
              "      <td>True</td>\n",
              "      <td>Improving Sentence Representations with Multi-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We show how discrete objects can be learnt in...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.9787233992575821, 0.33333332860555503, 0.41...</td>\n",
              "      <td>HJDUjKeA-</td>\n",
              "      <td>[We show how discrete objects can be learnt in...</td>\n",
              "      <td>True</td>\n",
              "      <td>Learning objects from pixels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Most recent gains in visual recognition have ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.11764705384083, 0.146341458655562, 0.199999...</td>\n",
              "      <td>BJgLg3R9KQ</td>\n",
              "      <td>[A large-scale dataset for training attention ...</td>\n",
              "      <td>True</td>\n",
              "      <td>Learning what and where to attend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[In recent years, deep neural networks have de...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.05882352484429101, 0.270270265887509, ...</td>\n",
              "      <td>BklpOo09tQ</td>\n",
              "      <td>[We proposed a time-efficient defense method a...</td>\n",
              "      <td>True</td>\n",
              "      <td>EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEE...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7911446c-75d4-4cf5-a01a-a7e619e5f13e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7911446c-75d4-4cf5-a01a-a7e619e5f13e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7911446c-75d4-4cf5-a01a-a7e619e5f13e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06315195-bf51-4618-bbde-3604a98e4144\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06315195-bf51-4618-bbde-3604a98e4144')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06315195-bf51-4618-bbde-3604a98e4144 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dftest",
              "summary": "{\n  \"name\": \"dftest\",\n  \"rows\": 618,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \"BkiIkBJ0b\",\n          \"rkeMHjR9Ym\",\n          \"r1xN5oA5tm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \"Do Deep Reinforcement Learning Algorithms really Learn to Navigate?\",\n          \"Stochastic Gradient Descent Learns State Equations with Nonlinear Activations\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop source_labels, rouge_scores, paper_id, ic and title from df\n",
        "df = df.drop(['source_labels', 'rouge_scores', 'paper_id', 'ic', 'title'], axis=1)\n",
        "dfval = dfval.drop(['source_labels', 'rouge_scores', 'paper_id', 'ic', 'title'], axis=1)\n",
        "dftest = dftest.drop(['source_labels', 'rouge_scores', 'paper_id', 'ic', 'title'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "itfP7lkUIWSX",
        "outputId": "32911f38-97b2-473d-9af5-b3c74e1aad6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Due to the success of deep learning to solvin...   \n",
              "1  [The backpropagation (BP) algorithm is often t...   \n",
              "2  [We introduce the 2-simplicial Transformer, an...   \n",
              "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
              "4  [Recent efforts on combining deep models with ...   \n",
              "\n",
              "                                              target  \n",
              "0  [We provide necessary and sufficient analytica...  \n",
              "1  [Biologically plausible learning algorithms, p...  \n",
              "2  [We introduce the 2-simplicial Transformer and...  \n",
              "3  [Accurate forecasting over very long time hori...  \n",
              "4  [We propose a variational message-passing algo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1269adf-f7e1-4d57-829c-adce3b3fd079\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Due to the success of deep learning to solvin...</td>\n",
              "      <td>[We provide necessary and sufficient analytica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
              "      <td>[Biologically plausible learning algorithms, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
              "      <td>[We introduce the 2-simplicial Transformer and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
              "      <td>[Accurate forecasting over very long time hori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Recent efforts on combining deep models with ...</td>\n",
              "      <td>[We propose a variational message-passing algo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1269adf-f7e1-4d57-829c-adce3b3fd079')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1269adf-f7e1-4d57-829c-adce3b3fd079 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1269adf-f7e1-4d57-829c-adce3b3fd079');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-195907fb-8e93-4cb0-b489-9fd4f05e8add\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-195907fb-8e93-4cb0-b489-9fd4f05e8add')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-195907fb-8e93-4cb0-b489-9fd4f05e8add button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ2OfP-UK0ka",
        "outputId": "494d6e74-55a0-4674-ce07-78c4ddddd55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1992 entries, 0 to 1991\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  1992 non-null   object\n",
            " 1   target  1992 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9iE4hgTIcx6",
        "outputId": "89eab205-cacc-4c4c-9ff7-dfc30e1aa7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 619 entries, 0 to 618\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  619 non-null    object\n",
            " 1   target  619 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hwX_SOnK_xw",
        "outputId": "77890cb2-d8aa-45f0-a087-a094e5f86c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 618 entries, 0 to 617\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  618 non-null    object\n",
            " 1   target  618 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Cleansing"
      ],
      "metadata": {
        "id": "izkHws86GsYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLcPk4kqIega",
        "outputId": "f59be483-5b11-4839-dfb7-c47d8c116762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleansing(df):\n",
        "    df_clean=df.astype(str).str.lower()\n",
        "    df_clean=[re.sub(r\"\\d+\",\"\",i )for i in df_clean]\n",
        "    df_clean=[re.sub(r'[^\\w]', ' ', i)for i in df_clean]\n",
        "    df_clean=[re.sub(r'\\s+',' ',i)for i in df_clean]\n",
        "    return df_clean"
      ],
      "metadata": {
        "id": "pap1khErIp8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text']=cleansing(df['source'])\n",
        "df['clean_target']=cleansing(df['target'])\n",
        "dfval['clean_text']=cleansing(dfval['source'])\n",
        "dfval['clean_target']=cleansing(dfval['target'])\n",
        "dftest['clean_text']=cleansing(dftest['source'])\n",
        "dftest['clean_target']=cleansing(dftest['target'])\n",
        "\n",
        "#drop original source and target\n",
        "df = df.drop(['source','target'], axis=1)\n",
        "dfval = dfval.drop(['source','target'], axis=1)\n",
        "dftest = dftest.drop(['source','target'], axis=1)"
      ],
      "metadata": {
        "id": "wSu-h95YIrkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bSGgRxArIveq",
        "outputId": "d1eaca2e-cc38-4499-f271-ea35412508d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          clean_text  \\\n",
              "0   due to the success of deep learning to solvin...   \n",
              "1   the backpropagation bp algorithm is often tho...   \n",
              "2   we introduce the simplicial transformer an ex...   \n",
              "3   we present tensor train rnn tt rnn a novel fa...   \n",
              "4   recent efforts on combining deep models with ...   \n",
              "\n",
              "                                        clean_target  \n",
              "0   we provide necessary and sufficient analytica...  \n",
              "1   biologically plausible learning algorithms pa...  \n",
              "2   we introduce the simplicial transformer and s...  \n",
              "3   accurate forecasting over very long time hori...  \n",
              "4   we propose a variational message passing algo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa974675-4aa8-45f3-aaff-bef62d8d2843\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>clean_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>due to the success of deep learning to solvin...</td>\n",
              "      <td>we provide necessary and sufficient analytica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the backpropagation bp algorithm is often tho...</td>\n",
              "      <td>biologically plausible learning algorithms pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we introduce the simplicial transformer an ex...</td>\n",
              "      <td>we introduce the simplicial transformer and s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we present tensor train rnn tt rnn a novel fa...</td>\n",
              "      <td>accurate forecasting over very long time hori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recent efforts on combining deep models with ...</td>\n",
              "      <td>we propose a variational message passing algo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa974675-4aa8-45f3-aaff-bef62d8d2843')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa974675-4aa8-45f3-aaff-bef62d8d2843 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa974675-4aa8-45f3-aaff-bef62d8d2843');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d307d348-7fbe-40d3-a5ee-2345aa0e5a41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d307d348-7fbe-40d3-a5ee-2345aa0e5a41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d307d348-7fbe-40d3-a5ee-2345aa0e5a41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1992,\n        \"samples\": [\n          \" most existing neural networks for learning graphs deal with the issue of permutation invariance by conceiving of the network as a message passing scheme where each node sums the feature vectors coming from its neighbors we argue that this imposes a limitation on their representation power and instead propose a new general architecture for representing objects consisting of a hierarchy of parts which we call covariant compositional networks ccns here covariance means that the activation of each neuron must transform in a specific way under permutations similarly to steerability in cnns we achieve covariance by making each activation transform according to a tensor representation of the permutation group and derive the corresponding tensor aggregation rules that each neuron must implement experiments show that ccns can outperform competing methods on some standard graph learning benchmarks learning on graphs has a long history in the kernels literature including approaches based on random walks bid bid bid counting subgraphs bid spectral ideas bid label propagation schemes with hashing bid neumann et al and even algebraic ideas bid many of these papers address moderate size problems in chemo and bioinformatics and the way they represent graphs is essentially fixed recently with the advent of deep learning and much larger datasets a sequence of neural network based approaches have appeared to address the same problem starting with bid in contrast to the kernels framework neural networks effectively integrate the classification or regression problem at hand with learning the graph representation itself in a single end to end system in the last few years there has been a veritable explosion in research activity in this area some of the proposed graph learning architectures bid bid bid directly seek inspiration from the type of classical cnns that are used for image recognition bid krizhevsky et al these methods involve first fixing a vertex ordering then moving a filter across vertices while doing some computation as a function of the local neighborhood to generate a representation this process is then repeated multiple times like in classical cnns to build a deep graph representation other notable works on graph neural networks include bid bid bid bid very recently bid showed that many of these approaches can be seen to be specific instances of a general message passing formalism and coined the term message passing neural networks mpnns to refer to them collectively while mpnns have been very successful in applications and are an active field of research they differ from classical cnns in a fundamental way the internal feature representations in cnns are equivariant to such transformations of the inputs as translation and rotations bid the internal representations in mpnns are fully invariant this is a direct result of the fact that mpnns deal with the permutation invariance issue in graphs simply by summing the messages coming from each neighbor in this paper we argue that this is a serious limitation that restricts the representation power of mpnns mpnns are ultimately compositional part based models that build up the representation of the graph from the representations of a hierarchy of subgraphs to address the covariance issue we study the covariance behavior of such networks in general introducing a new general class of neural network architectures which we call compositional networks comp nets one advantage of this generalization is that instead of focusing attention on the mechanics of how information propagates from node to node it emphasizes the connection to convolutional networks in particular it shows that what is missing from mpnns is essentially the analog of steerability steerability implies that the activations feature vectors at a given neuron must transform according to a specific representation in the algebraic sense of the symmetry group of its receptive field in our case the group of permutations s m in this paper we only consider the defining representation and its tensor products leading to first second third etc order tensor activations we derive the general form of covariant tensor propagation in comp nets and find that each channel in the network corresponds to a specific way of contracting a higher order tensor to a lower order one note that here by tensor activations we mean not just that each activation is expressed as a multidimensional array of numbers as the word is usually used in the neural networks literature but also that it transforms in a specific way under permutations which is a more stringent criterion the parameters of our covariant comp nets are the entries of the mixing matrix that prescribe how these channels communicate with each other at each node our experiments show that this new architecture can beat scalar message passing neural networks on several standard datasets on the subsampled hcep dataset ccn outperforms all other methods by a very large margin for the graph kernels datasets svm with the weisfeiler lehman kernels achieve the highest accuracy on nci and nci while ccn wins on mutag and ptc perhaps this poor performance is to be expected since the datasets are small and neural network approaches usually require tens of thousands of training examples at minimum to be effective indeed neural graph fingerprints and pscn also perform poorly compared to the weisfeiler lehman kernels in the qm experiments ccn beats the three other algorithms in both mean absolute error and root mean squared error it should be noted that bid obtained stronger results on qm but we cannot properly compare our results with theirs because our experiments only use the adjacency matrices and atom labels of each node while theirs includes comprehensive chemical features that better inform the target quantum properties we have presented a general framework called covariant compositional networks ccns for constructing covariant graph neural networks which encompasses other message passing approaches as special cases but takes a more general and principled approach to ensuring covariance with respect to permutations experimental results on several benchmark datasets show that ccns can outperform other state of the art algorithms clearly true since f a f a \\u03be a now assume that it is true for all nodes with height up to h for any node n a with h a h f a \\u03c6 f c f c f c k where each of the children c c k are of height at most h therefore f a \\u03c6 f c f c f c k \\u03c6 f c f c f c k f a thus f a f a for every node in g the proposition follows by \\u03c6 g f r f r \\u03c6 g proof of proposition let g g n and n be as in definition as in definition for each node neuron n i in n there is a node n j in n such that their receptive fields are equivalent up to permutation that is if p i m then p j m and there is a permutation \\u03c0 s m such that if p i e p e pm and p j e q e qm then e q \\u03c0 a e pa by covariance then f j r \\u03c0 f i now let g be a third equivalent object and n the corresponding comp net n must also have a node n k that corresponds to n i and n j in particular letting its receptive field be p k e r e rm there is a permutation \\u03c3 s m for which e r \\u03c3 b e q b therefore f k r \\u03c3 f j at the same time n k is also in correspondence with n i in particular letting \\u03c4 \\u03c3\\u03c0 which corresponds to first applying the permutation \\u03c0 then applying \\u03c3 e r \\u03c4 a e pa and therefore f k r \\u03c4 f i hence the r \\u03c0 maps must satisfy case follows directly from case finally if a a u are k th order p tensors and c j \\u03b1 j a j then displayform so c is a k th order p tensor proof of proposition under the action of a permutation \\u03c0 s m on p b \\u03c7 dropping the a b superscipt transforms to \\u03c7 where \\u03c7 i j \\u03c7 \\u03c0 i j however this can also be written as displayform therefore f i i k transforms to displayform so f is a p tensor proof of proposition by proposition under the action of any permutation \\u03c0 each of the f pj slices of f transforms as displayform at the same time \\u03c0 also permutes the slices amongst each other according to displayform so f is a k th order p tensor proof of proposition under any permutation \\u03c0 s m of p i a p i transforms to a p i where a p i \\u03c0 a \\u03c0 b a pi a b therefore a pi is a second order p tensor by the first case of proposition f a pi is then a k th order p tensor \",\n          \" generative models with both discrete and continuous latent variables are highly motivated by the structure of many real world data sets they present however subtleties in training often manifesting in the discrete latent variable not being leveraged in this paper we show why such models struggle to train using traditional log likelihood maximization and that they are amenable to training using the optimal transport framework of wasserstein autoencoders we find our discrete latent variable to be fully leveraged by the model when trained without any modifications to the objective function or significant fine tuning our model generates comparable samples to other approaches while using relatively simple neural networks since the discrete latent variable carries much of the descriptive burden furthermore the discrete latent provides significant control over generation unsupervised learning using generative latent variable models provides a powerful and general approach to learning the underlying low dimensional structure from large unlabeled datasets perhaps the two most common techniques for training such models are variational autoencoders vaes and generative adversarial networks gans bid both have advantages and disadvantages vaes provide a meaningful lower bound on the log likelihood that is stable under training as well as an encoding distribution from the data into the latent however they generate blurry samples due to their objective being unable to handle deterministic decoders and tractability requiring simple priors bid on the other hand gans naturally enable deterministic generative models with sharply defined samples but their training procedure is less stable a relatively new approach to training generative models has emerged based on minimizing the optimal transport ot distance bid between the generative model distribution and that of the data the ot approach provides a general framework for training generative models which promises some of the best of both gans and vaes though interesting first results have been given in bid the ot approach to generative modelling is still nascent our contributions are twofold we seek to improve generative modelling capabilities with discrete and continuous latent variables but importantly we seek also to establish that training generative models with ot can be significantly more effective than the traditional vae approach discrete latent variable models are critical to the endeavor of unsupervised learning because of the ubiquity of discreteness in the natural world and hence in the datasets that describe it however they are harder to train than their continuous counterparts this has been tackled in a number of ways e g directly mitigating high variance discrete samples bid bid parametrizing discrete distributions using continuous ones bid bid bid deliberate model design leveraging conjugacy however even in the simple case where the number of mixtures is small enough that monte carlo sampling from the discrete latent is avoidable training can still be problematic for example in bid a gaussian mixture latent variable model gm lvm was studied and the authors were unable to train their model on mnist using variational inference without substantially modifying the vae objective what appears to happen is that the model quickly learns to hack the vae objective function by collapsing the discrete latent variational distribution this problem only occurs in the unsupervised setting as are able to learn the discrete latent in the semi supervised version of the same problem once they have labeled samples for the discrete latent to latch onto this is discussed in more detail in section the ot approach to training generative models in particular the wasserstein distance discussed in section induces a weaker topology on the space of distributions enabling easier convergence of distributions than in the case of vaes bid thus one might conjecture that the ot approach would enable easier training of gm lvms than the vae approach we provide evidence that this is indeed the case showing that gm lvms can be trained in the unsupervised setting on mnist and motivating further the value of the ot approach to generative modelling we studied an unsupervised generative model with a mixture of gaussians latent variable structure well suited to data containing discrete classes of objects with continuous variation within each class we showed that such a simple and critical class of models fails to train using the vae framework in the sense that it immediately learns to discard its discrete latent structure we further exposed the root cause of this phenomenon with empirical results we then put to the test the abstract mathematical claim that the wasserstein distance induces a weaker topology on the space of distributions by attempting to train the same mixture of gaussians model in the wae framework we found the wasserstein objective is successful at training this model to leverage its discrete continuous latent structure fully we provided promising results on mnist and demonstrated the additional control available to a highly structured model with both discrete and continuous latent variables we hope this motivates further study of the exciting but nascent field of optimal transport in generative modeling \",\n          \" one of the distinguishing aspects of human language is its compositionality which allows us to describe complex environments with limited vocabulary previously it has been shown that neural network agents can learn to communicate in a highly structured possibly compositional language based on disentangled input e g hand engineered features humans however do not learn to communicate based on well summarized features in this work we train neural agents to simultaneously develop visual perception from raw image pixels and learn to communicate with a sequence of discrete symbols the agents play an image description game where the image contains factors such as colors and shapes we train the agents using the obverter technique where an agent introspects to generate messages that maximize its own understanding through qualitative analysis visualization and a zero shot test we show that the agents can develop out of raw image pixels a language with compositional properties given a proper pressure from the environment one of the key requirements for artificial general intelligence agi to thrive in the real world is its ability to communicate with humans in natural language natural language processing nlp has been an active field of research for a long time and the introduction of deep learning bid enabled great progress in nlp tasks such as translation image captioning text generation and visual question answering vinyals et al bid bid serban et al bid bid however training machines in a supervised manner with a large dataset has its limits when it comes to communication supervised methods are effective for capturing statistical associations between discrete symbols i e words letters the essence of communication is more than just predicting the most likely word to come next it is a means to coordinate with others and potentially achieve a common goal bid bid wittgenstein an alternative path to teaching machines the art of communication is to give them a specific task and encourage them to learn how to communicate on their own this approach will encourage the agents to use languages grounded to task related entities as well as communicate with other agents which is one of the ways humans learn to communicate bid recently there have been several notable works that demonstrated the emergence of communication between neural network agents even though each work produced very interesting results of its own in all cases communication was either achieved with a single discrete symbol as opposed to a sequence of discrete symbols bid bid or via a continuous value sukhbaatar et al bid not only is human communication un differentiable but also using a single discrete symbol is quite far from natural language communication one of the key features of human language is its compositional nature the meaning of a complex expression is determined by its structure and the meanings of its constituents bid more recently bid and bid trained the agents to communicate in grounded compositional language in both studies however inputs given to the agents were hand engineered features disentangled input rather than raw perceptual signals that we receive as humans in this work we train neural agents to simultaneously develop visual perception from raw image pixels and learn to communicate with a sequence of discrete symbols unlike previous works our setup poses greater challenges to the agents since visual understanding and discrete communication have to be induced from scratch in parallel we place the agents in a two person image description game where images contain objects of various color and shape inspired by the pioneering work of bid we employ a communication philosophy named obverter to train the agents having its root in the theory of mind premack woodruff and human language development bid the obverter technique motivates an agent to search over messages and generate the ones that maximize their own understanding the contribution of our work can be summarized as follows we train artificial agents to learn to disentangle raw image pixels and communicate in compositional language at the same time we describe how the obverter technique a differentiable learning algorithm for discrete communication could be employed in a communication game with raw visual input we visualize how the agents are perceiving the images and show that they learn to disentangle color and shape without any explicit supervision other than the communication one experiment results suggest that the agents could develop out of raw image input a language with compositional properties given a proper pressure from the environment i e the image description game finally while our exposition follows a multi agent perspective it is also possible to interpret our results in the single agent setting we are effectively learning a neural network that is able to learn disentangled compositional representations of visual scenes without any supervision subject to the constraints imposed by their environment our agents learn disentangled concepts and how to compose these to form new concepts this is an important milestone in the path to agi in this work we used the obverter technique to train neural network agents to communicate in a two person image description game through qualitative analysis visualization and the zero shot test we have shown that even though the agents receive raw perception in the form of image pixels under the right environment pressures the emerged language had properties consistent with the ones found in compositional languages as an evaluation strategy we followed previous works and focused on assessing the necessary conditions of compositional languages however the exact definition of compositional language is still somewhat debatable and to the best of our knowledge there is no reliable way to mathematically quantify the degree of compositionality of an arbitrary language therefore in order to encourage active research and discussion among researchers in this domain we propose for future work a quantitatively measurable definition of compositionality we believe compositionality of a language is not binary e g language a is compositional not compositional but a spectrum for example human language has some aspects that are compositional e g syntactic constructions most morphological combinations and some that are not e g irregular verb tenses in english character level word composition it is also important to clearly define grounded language and compositional language if one agent says abc eat red apple and another says cba apple red eat and they both understand each other are they speaking compositional language we believe such questions should be asked and addressed to shape the definition of compositionality in addition to the definition evaluation of compositional languages there are numerous directions of future work observing the emergence of a compositional language among more than two agents is an apparent next step designing an environment to motivate the agents to disentangle more than two factors is also an interesting direction training agents to consider the context i e pragmatics such as giving each agent several images instead of one is another exciting future work a emergence of grammar bid in bid the author successfully trained neural agents to develop a structured i e grammatical language using disentangled meaning vectors as the input using subject vectors and predicate vectors all represented as explicit binary vectors total meaning vectors could be composed tab each digit in the subject vector a serves a clear role respectively representing speaker sp hearer hr other ot and plural pl the predicate vector values on the other hand are randomly chosen so that each predicate vector will have three s and three s the combination of ten subject vectors and ten predicate vectors allows meaning vectors the author used twenty neural agents for the experiment each agent was implemented with the vanilla recurrent neural networks rnn where the hidden vector h s size was same as the size of the meaning vector m in order to treat h as the agent s understanding of m in each training round a single learner i e listener and ten teachers i e speaker were randomly chosen each teacher given all m s in random order generates a message s for each m and sends it to the learner the messages are generated using the obverter techinque which is described in algorithm the learner is trained to minimize the mean squared error mse between h after consuming the s and m after the learner has learned from all ten teachers the next round begins repeating the process until the error goes below some threshold algorithm message generation process used in bid displayform append i to s displayform terminate when the training was complete the author was able to find strong patterns in the messages used by the agents table note that the messages using predicates tired scared sick and happy especially follow a very clear pattern batali also conducted a zero shot test where the agents were trained without the diagonal elements in table and tested with all meaning vectors the agents were able to successfully communicate even when held out meaning vectors were used but the table top messages used by a majority of the population for each of the given meanings bottom a potential analysis of the system in terms of a root plus modifications italic symbols are used to specify predicates and roman symbols are used to specify subjects messages in parentheses cannot be made to fit into this analysis messages used for the held out meaning vectors did not show as strong compositional patterns as the non zero shot case \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          \" in this paper we propose a three dimensional regularization based pruning method to accelerate the d cnn \",\n          \" a graph neural network able to automatically learn and leverage a dynamic interactive graph structure \",\n          \" we train neural network agents to develop a language with compositional properties from raw pixel input \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\"clean_text\": \"text\", \"clean_target\": \"target\"}, inplace=True)\n",
        "dfval.rename(columns={\"clean_text\": \"text\", \"clean_target\": \"target\"}, inplace=True)\n",
        "dftest.rename(columns={\"clean_text\": \"text\", \"clean_target\": \"target\"}, inplace=True)"
      ],
      "metadata": {
        "id": "fmbMSa0cJAVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s9NIwvP4JZD7",
        "outputId": "ef8479fa-ff61-42fe-a20e-fcb6aa00e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   due to the success of deep learning to solvin...   \n",
              "1   the backpropagation bp algorithm is often tho...   \n",
              "2   we introduce the simplicial transformer an ex...   \n",
              "3   we present tensor train rnn tt rnn a novel fa...   \n",
              "4   recent efforts on combining deep models with ...   \n",
              "\n",
              "                                              target  \n",
              "0   we provide necessary and sufficient analytica...  \n",
              "1   biologically plausible learning algorithms pa...  \n",
              "2   we introduce the simplicial transformer and s...  \n",
              "3   accurate forecasting over very long time hori...  \n",
              "4   we propose a variational message passing algo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87aa6a69-0cf5-4c75-834f-cc211f2b66d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>due to the success of deep learning to solvin...</td>\n",
              "      <td>we provide necessary and sufficient analytica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the backpropagation bp algorithm is often tho...</td>\n",
              "      <td>biologically plausible learning algorithms pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we introduce the simplicial transformer an ex...</td>\n",
              "      <td>we introduce the simplicial transformer and s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we present tensor train rnn tt rnn a novel fa...</td>\n",
              "      <td>accurate forecasting over very long time hori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recent efforts on combining deep models with ...</td>\n",
              "      <td>we propose a variational message passing algo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87aa6a69-0cf5-4c75-834f-cc211f2b66d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87aa6a69-0cf5-4c75-834f-cc211f2b66d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87aa6a69-0cf5-4c75-834f-cc211f2b66d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e8bf65a-6ec4-46e0-87a7-7891bd0271e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e8bf65a-6ec4-46e0-87a7-7891bd0271e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e8bf65a-6ec4-46e0-87a7-7891bd0271e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1992,\n        \"samples\": [\n          \" most existing neural networks for learning graphs deal with the issue of permutation invariance by conceiving of the network as a message passing scheme where each node sums the feature vectors coming from its neighbors we argue that this imposes a limitation on their representation power and instead propose a new general architecture for representing objects consisting of a hierarchy of parts which we call covariant compositional networks ccns here covariance means that the activation of each neuron must transform in a specific way under permutations similarly to steerability in cnns we achieve covariance by making each activation transform according to a tensor representation of the permutation group and derive the corresponding tensor aggregation rules that each neuron must implement experiments show that ccns can outperform competing methods on some standard graph learning benchmarks learning on graphs has a long history in the kernels literature including approaches based on random walks bid bid bid counting subgraphs bid spectral ideas bid label propagation schemes with hashing bid neumann et al and even algebraic ideas bid many of these papers address moderate size problems in chemo and bioinformatics and the way they represent graphs is essentially fixed recently with the advent of deep learning and much larger datasets a sequence of neural network based approaches have appeared to address the same problem starting with bid in contrast to the kernels framework neural networks effectively integrate the classification or regression problem at hand with learning the graph representation itself in a single end to end system in the last few years there has been a veritable explosion in research activity in this area some of the proposed graph learning architectures bid bid bid directly seek inspiration from the type of classical cnns that are used for image recognition bid krizhevsky et al these methods involve first fixing a vertex ordering then moving a filter across vertices while doing some computation as a function of the local neighborhood to generate a representation this process is then repeated multiple times like in classical cnns to build a deep graph representation other notable works on graph neural networks include bid bid bid bid very recently bid showed that many of these approaches can be seen to be specific instances of a general message passing formalism and coined the term message passing neural networks mpnns to refer to them collectively while mpnns have been very successful in applications and are an active field of research they differ from classical cnns in a fundamental way the internal feature representations in cnns are equivariant to such transformations of the inputs as translation and rotations bid the internal representations in mpnns are fully invariant this is a direct result of the fact that mpnns deal with the permutation invariance issue in graphs simply by summing the messages coming from each neighbor in this paper we argue that this is a serious limitation that restricts the representation power of mpnns mpnns are ultimately compositional part based models that build up the representation of the graph from the representations of a hierarchy of subgraphs to address the covariance issue we study the covariance behavior of such networks in general introducing a new general class of neural network architectures which we call compositional networks comp nets one advantage of this generalization is that instead of focusing attention on the mechanics of how information propagates from node to node it emphasizes the connection to convolutional networks in particular it shows that what is missing from mpnns is essentially the analog of steerability steerability implies that the activations feature vectors at a given neuron must transform according to a specific representation in the algebraic sense of the symmetry group of its receptive field in our case the group of permutations s m in this paper we only consider the defining representation and its tensor products leading to first second third etc order tensor activations we derive the general form of covariant tensor propagation in comp nets and find that each channel in the network corresponds to a specific way of contracting a higher order tensor to a lower order one note that here by tensor activations we mean not just that each activation is expressed as a multidimensional array of numbers as the word is usually used in the neural networks literature but also that it transforms in a specific way under permutations which is a more stringent criterion the parameters of our covariant comp nets are the entries of the mixing matrix that prescribe how these channels communicate with each other at each node our experiments show that this new architecture can beat scalar message passing neural networks on several standard datasets on the subsampled hcep dataset ccn outperforms all other methods by a very large margin for the graph kernels datasets svm with the weisfeiler lehman kernels achieve the highest accuracy on nci and nci while ccn wins on mutag and ptc perhaps this poor performance is to be expected since the datasets are small and neural network approaches usually require tens of thousands of training examples at minimum to be effective indeed neural graph fingerprints and pscn also perform poorly compared to the weisfeiler lehman kernels in the qm experiments ccn beats the three other algorithms in both mean absolute error and root mean squared error it should be noted that bid obtained stronger results on qm but we cannot properly compare our results with theirs because our experiments only use the adjacency matrices and atom labels of each node while theirs includes comprehensive chemical features that better inform the target quantum properties we have presented a general framework called covariant compositional networks ccns for constructing covariant graph neural networks which encompasses other message passing approaches as special cases but takes a more general and principled approach to ensuring covariance with respect to permutations experimental results on several benchmark datasets show that ccns can outperform other state of the art algorithms clearly true since f a f a \\u03be a now assume that it is true for all nodes with height up to h for any node n a with h a h f a \\u03c6 f c f c f c k where each of the children c c k are of height at most h therefore f a \\u03c6 f c f c f c k \\u03c6 f c f c f c k f a thus f a f a for every node in g the proposition follows by \\u03c6 g f r f r \\u03c6 g proof of proposition let g g n and n be as in definition as in definition for each node neuron n i in n there is a node n j in n such that their receptive fields are equivalent up to permutation that is if p i m then p j m and there is a permutation \\u03c0 s m such that if p i e p e pm and p j e q e qm then e q \\u03c0 a e pa by covariance then f j r \\u03c0 f i now let g be a third equivalent object and n the corresponding comp net n must also have a node n k that corresponds to n i and n j in particular letting its receptive field be p k e r e rm there is a permutation \\u03c3 s m for which e r \\u03c3 b e q b therefore f k r \\u03c3 f j at the same time n k is also in correspondence with n i in particular letting \\u03c4 \\u03c3\\u03c0 which corresponds to first applying the permutation \\u03c0 then applying \\u03c3 e r \\u03c4 a e pa and therefore f k r \\u03c4 f i hence the r \\u03c0 maps must satisfy case follows directly from case finally if a a u are k th order p tensors and c j \\u03b1 j a j then displayform so c is a k th order p tensor proof of proposition under the action of a permutation \\u03c0 s m on p b \\u03c7 dropping the a b superscipt transforms to \\u03c7 where \\u03c7 i j \\u03c7 \\u03c0 i j however this can also be written as displayform therefore f i i k transforms to displayform so f is a p tensor proof of proposition by proposition under the action of any permutation \\u03c0 each of the f pj slices of f transforms as displayform at the same time \\u03c0 also permutes the slices amongst each other according to displayform so f is a k th order p tensor proof of proposition under any permutation \\u03c0 s m of p i a p i transforms to a p i where a p i \\u03c0 a \\u03c0 b a pi a b therefore a pi is a second order p tensor by the first case of proposition f a pi is then a k th order p tensor \",\n          \" generative models with both discrete and continuous latent variables are highly motivated by the structure of many real world data sets they present however subtleties in training often manifesting in the discrete latent variable not being leveraged in this paper we show why such models struggle to train using traditional log likelihood maximization and that they are amenable to training using the optimal transport framework of wasserstein autoencoders we find our discrete latent variable to be fully leveraged by the model when trained without any modifications to the objective function or significant fine tuning our model generates comparable samples to other approaches while using relatively simple neural networks since the discrete latent variable carries much of the descriptive burden furthermore the discrete latent provides significant control over generation unsupervised learning using generative latent variable models provides a powerful and general approach to learning the underlying low dimensional structure from large unlabeled datasets perhaps the two most common techniques for training such models are variational autoencoders vaes and generative adversarial networks gans bid both have advantages and disadvantages vaes provide a meaningful lower bound on the log likelihood that is stable under training as well as an encoding distribution from the data into the latent however they generate blurry samples due to their objective being unable to handle deterministic decoders and tractability requiring simple priors bid on the other hand gans naturally enable deterministic generative models with sharply defined samples but their training procedure is less stable a relatively new approach to training generative models has emerged based on minimizing the optimal transport ot distance bid between the generative model distribution and that of the data the ot approach provides a general framework for training generative models which promises some of the best of both gans and vaes though interesting first results have been given in bid the ot approach to generative modelling is still nascent our contributions are twofold we seek to improve generative modelling capabilities with discrete and continuous latent variables but importantly we seek also to establish that training generative models with ot can be significantly more effective than the traditional vae approach discrete latent variable models are critical to the endeavor of unsupervised learning because of the ubiquity of discreteness in the natural world and hence in the datasets that describe it however they are harder to train than their continuous counterparts this has been tackled in a number of ways e g directly mitigating high variance discrete samples bid bid parametrizing discrete distributions using continuous ones bid bid bid deliberate model design leveraging conjugacy however even in the simple case where the number of mixtures is small enough that monte carlo sampling from the discrete latent is avoidable training can still be problematic for example in bid a gaussian mixture latent variable model gm lvm was studied and the authors were unable to train their model on mnist using variational inference without substantially modifying the vae objective what appears to happen is that the model quickly learns to hack the vae objective function by collapsing the discrete latent variational distribution this problem only occurs in the unsupervised setting as are able to learn the discrete latent in the semi supervised version of the same problem once they have labeled samples for the discrete latent to latch onto this is discussed in more detail in section the ot approach to training generative models in particular the wasserstein distance discussed in section induces a weaker topology on the space of distributions enabling easier convergence of distributions than in the case of vaes bid thus one might conjecture that the ot approach would enable easier training of gm lvms than the vae approach we provide evidence that this is indeed the case showing that gm lvms can be trained in the unsupervised setting on mnist and motivating further the value of the ot approach to generative modelling we studied an unsupervised generative model with a mixture of gaussians latent variable structure well suited to data containing discrete classes of objects with continuous variation within each class we showed that such a simple and critical class of models fails to train using the vae framework in the sense that it immediately learns to discard its discrete latent structure we further exposed the root cause of this phenomenon with empirical results we then put to the test the abstract mathematical claim that the wasserstein distance induces a weaker topology on the space of distributions by attempting to train the same mixture of gaussians model in the wae framework we found the wasserstein objective is successful at training this model to leverage its discrete continuous latent structure fully we provided promising results on mnist and demonstrated the additional control available to a highly structured model with both discrete and continuous latent variables we hope this motivates further study of the exciting but nascent field of optimal transport in generative modeling \",\n          \" one of the distinguishing aspects of human language is its compositionality which allows us to describe complex environments with limited vocabulary previously it has been shown that neural network agents can learn to communicate in a highly structured possibly compositional language based on disentangled input e g hand engineered features humans however do not learn to communicate based on well summarized features in this work we train neural agents to simultaneously develop visual perception from raw image pixels and learn to communicate with a sequence of discrete symbols the agents play an image description game where the image contains factors such as colors and shapes we train the agents using the obverter technique where an agent introspects to generate messages that maximize its own understanding through qualitative analysis visualization and a zero shot test we show that the agents can develop out of raw image pixels a language with compositional properties given a proper pressure from the environment one of the key requirements for artificial general intelligence agi to thrive in the real world is its ability to communicate with humans in natural language natural language processing nlp has been an active field of research for a long time and the introduction of deep learning bid enabled great progress in nlp tasks such as translation image captioning text generation and visual question answering vinyals et al bid bid serban et al bid bid however training machines in a supervised manner with a large dataset has its limits when it comes to communication supervised methods are effective for capturing statistical associations between discrete symbols i e words letters the essence of communication is more than just predicting the most likely word to come next it is a means to coordinate with others and potentially achieve a common goal bid bid wittgenstein an alternative path to teaching machines the art of communication is to give them a specific task and encourage them to learn how to communicate on their own this approach will encourage the agents to use languages grounded to task related entities as well as communicate with other agents which is one of the ways humans learn to communicate bid recently there have been several notable works that demonstrated the emergence of communication between neural network agents even though each work produced very interesting results of its own in all cases communication was either achieved with a single discrete symbol as opposed to a sequence of discrete symbols bid bid or via a continuous value sukhbaatar et al bid not only is human communication un differentiable but also using a single discrete symbol is quite far from natural language communication one of the key features of human language is its compositional nature the meaning of a complex expression is determined by its structure and the meanings of its constituents bid more recently bid and bid trained the agents to communicate in grounded compositional language in both studies however inputs given to the agents were hand engineered features disentangled input rather than raw perceptual signals that we receive as humans in this work we train neural agents to simultaneously develop visual perception from raw image pixels and learn to communicate with a sequence of discrete symbols unlike previous works our setup poses greater challenges to the agents since visual understanding and discrete communication have to be induced from scratch in parallel we place the agents in a two person image description game where images contain objects of various color and shape inspired by the pioneering work of bid we employ a communication philosophy named obverter to train the agents having its root in the theory of mind premack woodruff and human language development bid the obverter technique motivates an agent to search over messages and generate the ones that maximize their own understanding the contribution of our work can be summarized as follows we train artificial agents to learn to disentangle raw image pixels and communicate in compositional language at the same time we describe how the obverter technique a differentiable learning algorithm for discrete communication could be employed in a communication game with raw visual input we visualize how the agents are perceiving the images and show that they learn to disentangle color and shape without any explicit supervision other than the communication one experiment results suggest that the agents could develop out of raw image input a language with compositional properties given a proper pressure from the environment i e the image description game finally while our exposition follows a multi agent perspective it is also possible to interpret our results in the single agent setting we are effectively learning a neural network that is able to learn disentangled compositional representations of visual scenes without any supervision subject to the constraints imposed by their environment our agents learn disentangled concepts and how to compose these to form new concepts this is an important milestone in the path to agi in this work we used the obverter technique to train neural network agents to communicate in a two person image description game through qualitative analysis visualization and the zero shot test we have shown that even though the agents receive raw perception in the form of image pixels under the right environment pressures the emerged language had properties consistent with the ones found in compositional languages as an evaluation strategy we followed previous works and focused on assessing the necessary conditions of compositional languages however the exact definition of compositional language is still somewhat debatable and to the best of our knowledge there is no reliable way to mathematically quantify the degree of compositionality of an arbitrary language therefore in order to encourage active research and discussion among researchers in this domain we propose for future work a quantitatively measurable definition of compositionality we believe compositionality of a language is not binary e g language a is compositional not compositional but a spectrum for example human language has some aspects that are compositional e g syntactic constructions most morphological combinations and some that are not e g irregular verb tenses in english character level word composition it is also important to clearly define grounded language and compositional language if one agent says abc eat red apple and another says cba apple red eat and they both understand each other are they speaking compositional language we believe such questions should be asked and addressed to shape the definition of compositionality in addition to the definition evaluation of compositional languages there are numerous directions of future work observing the emergence of a compositional language among more than two agents is an apparent next step designing an environment to motivate the agents to disentangle more than two factors is also an interesting direction training agents to consider the context i e pragmatics such as giving each agent several images instead of one is another exciting future work a emergence of grammar bid in bid the author successfully trained neural agents to develop a structured i e grammatical language using disentangled meaning vectors as the input using subject vectors and predicate vectors all represented as explicit binary vectors total meaning vectors could be composed tab each digit in the subject vector a serves a clear role respectively representing speaker sp hearer hr other ot and plural pl the predicate vector values on the other hand are randomly chosen so that each predicate vector will have three s and three s the combination of ten subject vectors and ten predicate vectors allows meaning vectors the author used twenty neural agents for the experiment each agent was implemented with the vanilla recurrent neural networks rnn where the hidden vector h s size was same as the size of the meaning vector m in order to treat h as the agent s understanding of m in each training round a single learner i e listener and ten teachers i e speaker were randomly chosen each teacher given all m s in random order generates a message s for each m and sends it to the learner the messages are generated using the obverter techinque which is described in algorithm the learner is trained to minimize the mean squared error mse between h after consuming the s and m after the learner has learned from all ten teachers the next round begins repeating the process until the error goes below some threshold algorithm message generation process used in bid displayform append i to s displayform terminate when the training was complete the author was able to find strong patterns in the messages used by the agents table note that the messages using predicates tired scared sick and happy especially follow a very clear pattern batali also conducted a zero shot test where the agents were trained without the diagonal elements in table and tested with all meaning vectors the agents were able to successfully communicate even when held out meaning vectors were used but the table top messages used by a majority of the population for each of the given meanings bottom a potential analysis of the system in terms of a root plus modifications italic symbols are used to specify predicates and roman symbols are used to specify subjects messages in parentheses cannot be made to fit into this analysis messages used for the held out meaning vectors did not show as strong compositional patterns as the non zero shot case \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          \" in this paper we propose a three dimensional regularization based pruning method to accelerate the d cnn \",\n          \" a graph neural network able to automatically learn and leverage a dynamic interactive graph structure \",\n          \" we train neural network agents to develop a language with compositional properties from raw pixel input \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t3rNjrmILkhL",
        "outputId": "4b85e2cb-18dd-49a7-92ca-2f2cce1c5313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   mixed precision training mpt is becoming a pr...   \n",
              "1   many real world problems e g object detection...   \n",
              "2   foveation is an important part of human visio...   \n",
              "3   we explore the concept of co design in the co...   \n",
              "4   batch normalization batchnorm has shown to be...   \n",
              "\n",
              "                                              target  \n",
              "0   we devise adaptive loss scaling to improve mi...  \n",
              "1   we present a novel approach for learning to p...  \n",
              "2   we compare object recognition performance on ...  \n",
              "3   we develop methods to train deep neural model...  \n",
              "4   investigation of how batchnorm causes adversa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b28551b0-2ec0-4a52-baa1-7d144f6787ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mixed precision training mpt is becoming a pr...</td>\n",
              "      <td>we devise adaptive loss scaling to improve mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>many real world problems e g object detection...</td>\n",
              "      <td>we present a novel approach for learning to p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>foveation is an important part of human visio...</td>\n",
              "      <td>we compare object recognition performance on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we explore the concept of co design in the co...</td>\n",
              "      <td>we develop methods to train deep neural model...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>batch normalization batchnorm has shown to be...</td>\n",
              "      <td>investigation of how batchnorm causes adversa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b28551b0-2ec0-4a52-baa1-7d144f6787ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b28551b0-2ec0-4a52-baa1-7d144f6787ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b28551b0-2ec0-4a52-baa1-7d144f6787ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd27e6d2-7e99-4373-a8c5-c3848a1bc66c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd27e6d2-7e99-4373-a8c5-c3848a1bc66c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd27e6d2-7e99-4373-a8c5-c3848a1bc66c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfval",
              "summary": "{\n  \"name\": \"dfval\",\n  \"rows\": 619,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \" the interpretability of neural networks has become crucial for their applications in real world with respect to the reliability and trustworthiness existing explanation generation methods usually provide important features by scoring their individual contributions to the model prediction and ignore the interactions between features which eventually provide a bag of words representation as explanation in natural language processing this type of explanations is challenging for human user to understand the meaning of an explanation and draw the connection between explanation and model prediction especially for long texts in this work we focus on detecting the interactions between features and propose a novel approach to build a hierarchy of explanations based on feature interactions the proposed method is evaluated with three neural classifiers lstm cnn and bert on two benchmark text classification datasets the generated explanations are assessed by both automatic evaluation measurements and human evaluators experiments show the effectiveness of the proposed method in providing explanations that are both faithful to models and understandable to humans deep neural networks have become a significant component in natural language processing nlp achieving state of the art performance in various nlp tasks such as text classification kim question answering rajpurkar et al and machine translation bahdanau et al however the lack of understanding on their decision making leads them to be characterized as black box models and increases the risk of applying them in real world applications lipton producing interpretable decisions has been a critical factor on whether people will trust and use the neural network models ribeiro et al most of existing work on local explanation generation for nlp focuses on producing word level explanations ribeiro et al lei et al plumb et al where a local explanation consists of a set of words extracted from the original text figure presents an example sentence with its sentiment prediction and corresponding word level explanation generated by lime ribeiro et al although the lime explanation captures a negative sentiment word waste it presents the explanation in a bag of words format without resorting to the original text it is difficult for us to understand the contribution of word a and of as both of them have no sentiment polarity the situation will become even more serious when this type of explanations are extracted from longer texts in this work we present a novel method to construct hierarchical explanations of a model prediction by capturing the interaction between features ultimately our method is able to produce a hierarchical structure as illustrated in figure produced by the proposed method this example provides a comprehensive picture of how different granularity of features interacting with each other for model prediction with the hierarchical structure this example tells us how the words and phrases are combined and what are the contributions of words and phrases to the final prediction for example the contribution of the phrase of good is dominated by the word waste which eventually leads to the right prediction figure a negative movie review a waste of good performance with a lime explanation and a hierarchical explanation where the color of each block represents the importance of the corresponding word phrase with respect to the model prediction to capture feature interactions we adopt the interacted shapley value lundberg et al an extension of shapley value shapley from cooperative game theory to measure the interactions between features based on the interaction scores we propose a top down method called intershapley to segment a text recursively into phrases and then words eventually the proposed method is evaluated on text classification tasks with three typical neural network models long short term memory networks hochreiter schmidhuber lstm and convolutional neural networks kim cnn and a state of the art model bert devlin et al on some benchmark datasets the comparison of our method is against several competitive baselines from prior work on explanation generation including leave one out li et al contextual decomposition cd murdoch et al and its hierarchical extension acd singh et al l and c shapley chen et al and lime ribeiro et al our contribution of this work is three fold we propose an effective method to calculate feature importance and extend the shapley value to measure feature interactions we design a top down segmentation algorithm to build hierarchical interpretations based on feature interactions we compare the proposed method with several competitive baselines via both automatic and human evaluations and show the intershapley method outperforms the existing methods on both wordand phrase level explanations \",\n          \" learning multilingual representations of text has proven a successful method for many cross lingual transfer learning tasks there are two main paradigms for learning such representations alignment which maps different independently trained monolingual representations into a shared space and joint training which directly learns unified multilingual representations using monolingual and cross lingual objectives jointly in this paper we first conduct direct comparisons of representations learned using both of these methods across diverse cross lingual tasks our empirical results reveal a set of pros and cons for both methods and show that the relative performance of alignment versus joint training is task dependent stemming from this analysis we propose a simple and novel framework that combines these two previously mutually exclusive approaches extensive experiments on various tasks demonstrate that our proposed framework alleviates limitations of both approaches and outperforms existing methods on the muse bilingual lexicon induction bli benchmark we further show that our proposed framework can generalize to contextualized representations and achieves state of the art results on the conll cross lingual ner benchmark continuous word representations mikolov et al a pennington et al bojanowski et al have become ubiquitous across a wide range of nlp tasks in particular methods for crosslingual word embeddings clwe have proven a powerful tool for cross lingual transfer for downstream tasks such as text classification klementiev et al a dependency parsing ahmad et al named entity recognition ner xie et al chen et al natural language inference language modeling adams et al and machine translation mt zou et al artetxe et al b the goal of these clwe methods is to learn embeddings in a shared vector space for two or more languages there are two main paradigms for learning clwe cross lingual alignment and joint training the most successful approach has been the cross lingual embedding alignment method mikolov et al b which relies on the assumption that monolingually trained continuous word embedding spaces share similar structure across different languages the underlying idea is to first independently train embeddings in different languages using monolingual corpora alone and then learn a mapping to align them to a shared vector space such a mapping can be trained in a supervised fashion using parallel resources such as bilingual lexicons xing et al smith et al joulin et al b jawanpuria et al or even in an unsupervised manner based on distribution matching zhang et al a artetxe et al a zhou et al recently it has been shown that alignment methods can also be effectively applied to contextualized word representations schuster et al aldarmaki diab another successful line of research for clwe considers joint training methods which optimize a monolingual objective predicting the context of a word in a monolingual corpus along with either a code will be released on publication in this paper supervision refers to that provided by a parallel corpus or bilingual dictionaries hard or soft cross lingual constraint similar to alignment methods some early works rely on bilingual dictionaries ammar et al duong et al or parallel corpora luong et al for direct supervision more recently a seemingly naive unsupervised joint training approach has received growing attention due to its simplicity and effectiveness in particular reports that simply training embeddings on concatenated monolingual corpora of two related languages using a shared vocabulary without any cross lingual resources is able to produce higher accuracy than the more sophisticated alignment methods on unsupervised mt tasks besides for contextualized representations unsupervised multilingual language model pretraining using a shared vocabulary has produced state of the art results on multiple benchmarks devlin et al artetxe schwenk lample conneau despite a large amount of research on both alignment and joint training previous work has neither performed a systematic comparison between the two analyzed their pros and cons nor elucidated when we may prefer one method over the other particularly it s natural to ask does the phenomenon reported in extend to other cross lingual tasks can we employ alignment methods to further improve their proposed unsupervised joint training if so how would such a framework compare to supervised joint training methods that exploit equivalent resources and lastly can this framework generalize to contextualized representations in this work we attempt to address these questions specifically we first evaluate and compare alignment versus joint training methods across three diverse tasks bli cross lingual ner and unsupervised mt we seek to characterize the conditions under which one approach outperforms the other and glean insight on the reasons behind these differences based on our analysis we further propose a simple novel and highly generic framework that uses unsupervised joint training as initialization and alignment as refinement to combine both paradigms our experiments demonstrate that our framework improves over both alignment and joint training baselines and outperforms existing methods on the muse bli benchmark moreover we show that our framework can generalize to contextualized representations producing state of the art results on the conll cross lingual ner benchmark to the best of our knowledge this is the first framework that combines previously mutually exclusive alignment and joint training methods in this paper we systematically compare the alignment and joint training methods for clwe we point out that the nature of each category of methods leads to certain strengths and limitations the empirical experiments on extensive benchmark datasets and various nlp tasks verified our analysis to further improve the state of art of clwe we propose a simple hybrid framework which combines the strength from both worlds and achieves significantly better performance in the bli mt and ner tasks our work opens a promising new direction that combines two previously exclusive lines of research for future work an interesting direction is to find a more optimal word sharing strategy \",\n          \" we study the convergence of gradient descent gd and stochastic gradient descent sgd for training l hidden layer linear residual networks resnets we prove that for training deep residual networks with certain linear transformations at input and output layers which are fixed throughout training both gd and sgd with zero initialization on all hidden weights can converge to the global minimum of the training loss moreover when specializing to appropriate gaussian random linear transformations gd and sgd provably optimize wide enough deep linear resnets compared with the global convergence result of gd for training standard deep linear networks citep duwidth our condition on the neural network width is sharper by a factor of o kappa l where kappa denotes the condition number of the covariance matrix of the training data in addition for the first time we establish the global convergence of sgd for training deep linear resnets and prove a linear convergence rate when the global minimum is despite the remarkable power of deep neural networks dnns trained using stochastic gradient descent sgd in many machine learning applications theoretical understanding of the properties of this algorithm or even plain gradient descent gd remains limited many key properties of the learning process for such systems are also present in the idealized case of deep linear networks for example a the objective function is not convex b errors back propagate and c there is potential for exploding and vanishing gradients in addition to enabling study of systems with these properties in a relatively simple setting analysis of deep linear networks also facilitates the scientific understanding of deep learning because using linear networks can control for the effect of architecture choices on the expressiveness of networks arora et al du hu for these reasons deep linear networks have received extensive attention in recent years one important line of theoretical investigation of deep linear networks concerns optimization landscape analysis kawaguchi hardt ma freeman bruna lu kawaguchi yun et al zhou liang where major findings include that any critical point of a deep linear network with square loss function is either a global minimum or a saddle point and identifying conditions on the weight matrices that exclude saddle points beyond landscape analysis another research direction aims to establish convergence guarantees for optimization algorithms e g gd sgd for training deep linear networks arora et al studied the trajectory of gradient flow and showed that depth can help accelerate the optimization of deep linear networks ji telgarsky gunasekar et al investigated the implicit bias of gd for training deep linear networks and deep linear convolutional networks respectively more recently bartlett et al arora et al a shamir du hu analyzed the optimization trajectory of gd for training deep linear networks and proved global convergence rates under certain assumptions on the training data initialization and neural network structure inspired by the great empirical success of residual networks resnets hardt ma considered identity parameterizations in deep linear networks i e parameterizing each layer s weight matrix as i w which leads to the so called deep linear resnets in particular hardt ma established the existence of small norm solutions for deep residual networks with sufficiently large depth l and proved that there are no critical points other than the global minimum when the maximum spectral norm among all weight matrices is smaller than op lq motivated by this intriguing finding bartlett et al studied the convergence rate of gd for training deep linear networks with identity initialization which is equivalent to zero initialization in deep linear resnets they assumed whitened data and showed that gd can converge to the global minimum if i the training loss at the initialization is very close to optimal or ii the regression matrix \\u03c6 is symmetric and positive definite in fact they proved that when \\u03c6 is symmetric and has negative eigenvalues gd for linear resnets with zero initialization does not converge arora et al a showed that gd converges under substantially weaker conditions which can be satisfied by random initialization schemes the convergence theory of stochastic gradient descent for training deep linear resnets is largely missing it remains unclear under which conditions sgd can be guaranteed to find the global minimum in this paper we establish the global convergence of both gd and sgd for training deep linear resnets without any condition on the training data more specifically we consider the training of l hidden layer deep linear resnets with fixed linear transformations at input and output layers we prove that under certain conditions on the input and output linear transformations gd and sgd can converge to the global minimum of the training loss function moreover when specializing to appropriate gaussian random linear transformations we show that as long as the neural network is wide enough both gd and sgd with zero initialization on all hidden weights can find the global minimum there are two main ingredients of our proof i establishing restricted gradient bounds and a smoothness property and ii proving that these properties hold along the optimization trajectory and further lead to global convergence we point out the second aspect is challenging especially for sgd due to the uncertainty of its optimization trajectory caused by stochastic gradients we summarize our main contributions as follows we prove the global convergence of gd and sgd for training deep linear resnets specifically we derive a generic condition on the input and output linear transformations under which both gd and sgd with zero initialization on all hidden weights can find global minima based on this condition one can design a variety of input and output transformations for training deep linear resnets when applying appropriate gaussian random linear transformations we show that as long as the neural network width satisfies m \\u03c9pkr\\u03ba q with high probability gd can converge to the global minimum up to an error within op\\u03ba logp qq iterations where k r are the output dimension and the rank of training data matrix x respectively and \\u03ba x \\u03c3 r pxq denotes the condition number of the covariance matrix of the training data compared with previous convergence results for training deep linear networks from du hu our condition on the neural network width is independent of the neural network depth l and is strictly better by a factor of opl\\u03baq using the same gaussian random linear transformations we also establish the convergence guarantee of sgd for training deep linear resnets we show that if the neural network width satisfies m r \\u03c9 kr\\u03ba log p q n b with constant probability sgd can converge to the global minimum up to an error within r o \\u03ba logp q n b iterations where n is the training sample size and b is the minibatch size of stochastic gradient this is the first global convergence rate of sgd for training deep linear networks moreover when the global minimum of the training loss is we prove that sgd can further achieve linear rate of global convergence and the condition on the neural network width does not depend on the target error as alluded to above we analyze networks with d inputs k outputs and m \\u011b maxtd ku nodes in each hidden layer linear transformations that are fixed throughout training map the inputs to the first hidden layer and the last hidden layer to the outputs we prove that our bounds hold with high probability when these input and output transformations are randomly generated by gaussian distributions if instead the input transformation simply copies the inputs onto the first d components of the first hidden layer and the output transformation takes the first k components of the last hidden layer then our analysis does not provide a guarantee there is a good reason for this a slight modification of a lower bound argument from bartlett et al demonstrates that gd may fail to converge in this case however we describe a similarly simple deterministic choice of input and output transformations such that wide enough networks always converge the resulting condition on the network width is weaker than that for gaussian random transformations and thus improves on the corresponding convergence guarantee for linear networks which in addition to requiring wider networks only hold with high probability for random transformations in this section we will discuss several different choices of linear transformations at input and output layers and their effects to the convergence performance for simplicity we will only consider the condition for gd as we stated in subsection gd converges if the input and output weight matrices a and b then it is interesting to figure out what kind of choice of a and b can satisfy this condition in proposition we showed that gaussian random transformations i e each entry of a and b is generated from certain gaussian distribution satisfy this condition with high probability so that gd converges here we will discuss the following two other transformations identity transformations we first consider the transformations that a ri d\\u02c6d d\\u02c6pm dq s j and b a m k ri k\\u02c6k k\\u02c6pm kq s which is equivalent to the setting in bartlett et al when m k d then it is clear that \\u03c3 min pbq \\u03c3 max pbq a m k and \\u03c3 min paq \\u03c3 max paq now let us consider lpw pq q by our choices of b and a and zero initialization on weight matrices in hidden layers in the case that d k we have could be as big as f for example when x and y are orthogonal then plugging these results into the condition on a and b becomes where the second inequality is due to the fact that lpw q \\u010f y f then it is clear if x f \\u011b c the above inequality cannot be satisfied for any choice of m since it will be cancelled out on both sides of the inequality therefore in such cases our bound does not guarantee that gd achieves global convergence thus it is consistent with the non convergence results in bartlett et al note that replacing the scaling factor a m k in the definition of b with any other function of d k and m would not help gaussian random initialization on hidden weights where the input and output weights are generated by random initialization and remain fixed throughout the training modified identity transformations in fact we show that a different type of identity transformations of a and b can satisfy the condition here we provide one such example assuming m \\u011b d k we can construct two sets s s \\u0103 rms satisfying then we construct matrices a and b as follows where \\u03b1 is a parameter which will be specified later in this way it can be verified that ba \\u03c3 min paq \\u03c3 max paq and \\u03c3 min pbq \\u03c3 max pbq \\u03b1 thus it is clear that the initial training loss satisfies lpw pq q y f then plugging these results into the condition on a and b can be rewritten as the r h s of the above inequality does not depend on \\u03b1 which implies that we can choose sufficiently large \\u03b1 to make this inequality hold thus gd can be guaranteed to achieve the global convergence moreover it is worth noting that using modified identity transformation a neural network with m d k suffices to guarantee the global convergence of gd we further remark that similar analysis can be extended to sgd in this paper we proved the global convergence of gd and sgd for training deep linear resnets with square loss more specifically we considered fixed linear transformations at both input and output layers and proved that under certain conditions on the transformations gd and sgd with zero initialization on all hidden weights can converge to the global minimum in addition we further proved that when specializing to appropriate gaussian random linear transformations gd and sgd can converge as long as the neural network is wide enough when w is staying inside a certain region its proof is in section b lemma a let \\u03c4 l then for any weight matrices satisfying max lprls w l \\u010f it holds that in addition the stochastic gradient g l in algorithm satisfies where b is the minibatch size the gradient lower bound can be also interpreted as the polyak \\u0142ojasiewicz condition which is essential to the linear convergence rate the gradient upper bound is crucial to bound the trajectory length since this lemma requires that max lprls w l \\u010f the following lemma proves the smoothness property of the training loss function lpwq when w is staying inside a certain region its proof is in section b lemma a let \\u03c4 l then for any two collections of weight matrices denoted by based on these two lemmas we are able to complete the proof of all theorems which are provided as follows \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 619,\n        \"samples\": [\n          \" a novel approach to construct hierarchical explanations for text classification by detecting feature interactions a novel method for providing explanations for predicitions made by text classifiers that outperforms baselines on word level importance scores and a new metric cohesion loss to evaluate span level importance an interpretation method based on feature interactions and feature importance score as compared to independent feature contributions \",\n          \" we conduct a comparative study of cross lingual alignment vs joint training methods and unify these two previously exclusive paradigms in a new framework this paper compares approaches to bilingual lexicon induction and shows which method performs better on lexicon induction and ner and mt tasks \",\n          \" under certain condition on the input and output linear transformations both gd and sgd can achieve global convergence for training deep linear resnets the authors study the convergence of gradient descent in training deep linear residual networks and establish a global convergence of gd sgd and linear convergence rates of sg sgd study of convergence properties of gd and sgd on deep linear resnets and proof that under certain conditions on the input and output transformations and with zero initialization gd and sgd converges to global minima \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df\n",
        "val_df = dfval\n",
        "test_df = dftest\n",
        "\n",
        "print(f\"Training size: {len(train_df)}, Validation size: {len(val_df)}, Testing size: {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij3I6FpUMTwn",
        "outputId": "4316ba62-d127-4293-ccfb-293f0a25c749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 1992, Validation size: 619, Testing size: 618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class SummarizationDataset(Dataset): # class Cleansing yang final\n",
        "#     def __init__(self, dataframe, tokenizer, max_input_len=128, max_output_len=128):\n",
        "#         self.data = dataframe\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_input_len = max_input_len\n",
        "#         self.max_output_len = max_output_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         row = self.data.iloc[idx]\n",
        "#         #source = row[\"text\"]\n",
        "#         source = \"summarize: \" + \" \".join(row[\"text\"])\n",
        "#         target = row[\"target\"]\n",
        "\n",
        "#         source_encodings = self.tokenizer(\n",
        "#             source,\n",
        "#             max_length=self.max_input_len,\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "#         target_encodings = self.tokenizer(\n",
        "#             target,\n",
        "#             max_length=self.max_output_len,\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             \"input_ids\": source_encodings[\"input_ids\"].squeeze(),\n",
        "#             \"attention_mask\": source_encodings[\"attention_mask\"].squeeze(),\n",
        "#             \"labels\": target_encodings[\"input_ids\"].squeeze(),\n",
        "#         }\n"
      ],
      "metadata": {
        "id": "ixTOQ4dvMW0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# class SCITldrDataset(Dataset): # class buat NonCleansing yang final\n",
        "#     def __init__(self, dataset, tokenizer, max_input_len=512, max_output_len=128):\n",
        "#         self.dataset = dataset  # Save the dataset object directly\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_input_len = max_input_len\n",
        "#         self.max_output_len = max_output_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.dataset)  # Use the length of the dataset\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         # Access the data entry using .iloc to ensure integer-based indexing\n",
        "#         item = self.dataset.iloc[idx]\n",
        "#         # Join the list of strings in 'source' into a single string\n",
        "#         input_text = \"summarize: \" + \" \".join(item[\"source\"])\n",
        "#         target_text = item[\"target\"]\n",
        "#         # Tokenize input and output\n",
        "#         inputs = self.tokenizer(\n",
        "#             input_text,\n",
        "#             max_length=self.max_input_len,\n",
        "#             truncation=True,\n",
        "#             padding=\"max_length\",\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "#         targets = self.tokenizer(\n",
        "#             target_text,\n",
        "#             max_length=self.max_output_len,\n",
        "#             truncation=True,\n",
        "#             padding=\"max_length\",\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "#             \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "#             \"labels\": targets[\"input_ids\"].squeeze(),\n",
        "#         }"
      ],
      "metadata": {
        "id": "EOKqCUvE_JUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummarizationDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_input_len=128, max_output_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_output_len = max_output_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        # source = row[\"clean_text\"]\n",
        "        source = \"summarize: \" + row[\"text\"] # correct prefix\n",
        "        target = row[\"target\"]\n",
        "\n",
        "        source_encodings = self.tokenizer(\n",
        "            source,\n",
        "            max_length=self.max_input_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target_encodings = self.tokenizer(\n",
        "            target,\n",
        "            max_length=self.max_output_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source_encodings[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": source_encodings[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target_encodings[\"input_ids\"].squeeze(),\n",
        "        }"
      ],
      "metadata": {
        "id": "V8movtDJQ6is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"t5-small\"  # Change to 't5-base' or larger if needed\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_OJqbV5MYvl",
        "outputId": "21c401f3-6c26-4658-d147-8f4173f26f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets\n",
        "train_dataset = SummarizationDataset(train_df, tokenizer) # pake yang cleansing karena nama collumnnya beda\n",
        "val_dataset = SummarizationDataset(val_df, tokenizer)\n",
        "test_dataset = SummarizationDataset(test_df, tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n"
      ],
      "metadata": {
        "id": "L3XyEofNMakf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training arc"
      ],
      "metadata": {
        "id": "4M4x8ci0IXl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5w)\n",
        "\n",
        "epochs = 10  # Maximum epochs\n",
        "patience = 3  # Early stopping patience\n",
        "best_val_loss = float(\"inf\")\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print progress\n",
        "        if (step + 1) % 10 == 0:\n",
        "            print(f\"Step {step + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels,\n",
        "            )\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(\"Best model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-VlwACIMgTM",
        "outputId": "55cafbc3-29d1-48c5-d8f8-5afd6d720437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10/249, Loss: 8.8274\n",
            "Step 20/249, Loss: 4.7012\n",
            "Step 30/249, Loss: 2.2826\n",
            "Step 40/249, Loss: 1.6839\n",
            "Step 50/249, Loss: 1.6034\n",
            "Step 60/249, Loss: 1.5220\n",
            "Step 70/249, Loss: 1.4586\n",
            "Step 80/249, Loss: 1.2379\n",
            "Step 90/249, Loss: 1.0430\n",
            "Step 100/249, Loss: 1.1454\n",
            "Step 110/249, Loss: 1.2393\n",
            "Step 120/249, Loss: 0.9724\n",
            "Step 130/249, Loss: 1.0438\n",
            "Step 140/249, Loss: 0.9872\n",
            "Step 150/249, Loss: 0.8139\n",
            "Step 160/249, Loss: 1.1218\n",
            "Step 170/249, Loss: 1.0320\n",
            "Step 180/249, Loss: 1.0165\n",
            "Step 190/249, Loss: 0.8853\n",
            "Step 200/249, Loss: 1.0418\n",
            "Step 210/249, Loss: 0.6661\n",
            "Step 220/249, Loss: 0.9682\n",
            "Step 230/249, Loss: 0.9858\n",
            "Step 240/249, Loss: 0.7620\n",
            "Epoch 1 Training Loss: 1.8753\n",
            "Epoch 1 Validation Loss: 2.2649\n",
            "Best model saved.\n",
            "Epoch 2/10\n",
            "Step 10/249, Loss: 0.7648\n",
            "Step 20/249, Loss: 0.8039\n",
            "Step 30/249, Loss: 0.9509\n",
            "Step 40/249, Loss: 1.1215\n",
            "Step 50/249, Loss: 0.8668\n",
            "Step 60/249, Loss: 0.6120\n",
            "Step 70/249, Loss: 0.8131\n",
            "Step 80/249, Loss: 0.8611\n",
            "Step 90/249, Loss: 0.9489\n",
            "Step 100/249, Loss: 0.9689\n",
            "Step 110/249, Loss: 0.8251\n",
            "Step 120/249, Loss: 0.7500\n",
            "Step 130/249, Loss: 0.8358\n",
            "Step 140/249, Loss: 0.8584\n",
            "Step 150/249, Loss: 0.9656\n",
            "Step 160/249, Loss: 0.8530\n",
            "Step 170/249, Loss: 0.6552\n",
            "Step 180/249, Loss: 0.5158\n",
            "Step 190/249, Loss: 0.7980\n",
            "Step 200/249, Loss: 1.0200\n",
            "Step 210/249, Loss: 0.8667\n",
            "Step 220/249, Loss: 0.9750\n",
            "Step 230/249, Loss: 0.7170\n",
            "Step 240/249, Loss: 0.7069\n",
            "Epoch 2 Training Loss: 0.8287\n",
            "Epoch 2 Validation Loss: 2.1495\n",
            "Best model saved.\n",
            "Epoch 3/10\n",
            "Step 10/249, Loss: 0.7900\n",
            "Step 20/249, Loss: 0.7038\n",
            "Step 30/249, Loss: 0.6735\n",
            "Step 40/249, Loss: 0.6474\n",
            "Step 50/249, Loss: 0.7363\n",
            "Step 60/249, Loss: 0.8777\n",
            "Step 70/249, Loss: 0.7067\n",
            "Step 80/249, Loss: 0.7960\n",
            "Step 90/249, Loss: 0.9052\n",
            "Step 100/249, Loss: 0.6692\n",
            "Step 110/249, Loss: 0.8740\n",
            "Step 120/249, Loss: 0.7886\n",
            "Step 130/249, Loss: 0.6289\n",
            "Step 140/249, Loss: 0.7185\n",
            "Step 150/249, Loss: 0.6477\n",
            "Step 160/249, Loss: 0.8366\n",
            "Step 170/249, Loss: 0.6482\n",
            "Step 180/249, Loss: 0.7312\n",
            "Step 190/249, Loss: 0.7386\n",
            "Step 200/249, Loss: 0.5704\n",
            "Step 210/249, Loss: 0.6046\n",
            "Step 220/249, Loss: 0.6076\n",
            "Step 230/249, Loss: 0.7957\n",
            "Step 240/249, Loss: 0.6434\n",
            "Epoch 3 Training Loss: 0.7352\n",
            "Epoch 3 Validation Loss: 2.0947\n",
            "Best model saved.\n",
            "Epoch 4/10\n",
            "Step 10/249, Loss: 0.6878\n",
            "Step 20/249, Loss: 0.8055\n",
            "Step 30/249, Loss: 0.6557\n",
            "Step 40/249, Loss: 0.8425\n",
            "Step 50/249, Loss: 0.6847\n",
            "Step 60/249, Loss: 0.6701\n",
            "Step 70/249, Loss: 0.8038\n",
            "Step 80/249, Loss: 0.5328\n",
            "Step 90/249, Loss: 0.7883\n",
            "Step 100/249, Loss: 0.8829\n",
            "Step 110/249, Loss: 0.8234\n",
            "Step 120/249, Loss: 0.6237\n",
            "Step 130/249, Loss: 0.6954\n",
            "Step 140/249, Loss: 0.9303\n",
            "Step 150/249, Loss: 0.7398\n",
            "Step 160/249, Loss: 0.5975\n",
            "Step 170/249, Loss: 0.6057\n",
            "Step 180/249, Loss: 0.7074\n",
            "Step 190/249, Loss: 0.8278\n",
            "Step 200/249, Loss: 0.5189\n",
            "Step 210/249, Loss: 0.8080\n",
            "Step 220/249, Loss: 0.7964\n",
            "Step 230/249, Loss: 0.6570\n",
            "Step 240/249, Loss: 0.6670\n",
            "Epoch 4 Training Loss: 0.6959\n",
            "Epoch 4 Validation Loss: 2.0648\n",
            "Best model saved.\n",
            "Epoch 5/10\n",
            "Step 10/249, Loss: 0.5462\n",
            "Step 20/249, Loss: 0.9040\n",
            "Step 30/249, Loss: 0.7977\n",
            "Step 40/249, Loss: 0.5874\n",
            "Step 50/249, Loss: 0.3976\n",
            "Step 60/249, Loss: 0.8867\n",
            "Step 70/249, Loss: 0.6674\n",
            "Step 80/249, Loss: 0.7500\n",
            "Step 90/249, Loss: 0.4665\n",
            "Step 100/249, Loss: 0.7272\n",
            "Step 110/249, Loss: 0.6005\n",
            "Step 120/249, Loss: 0.7653\n",
            "Step 130/249, Loss: 0.5761\n",
            "Step 140/249, Loss: 0.6539\n",
            "Step 150/249, Loss: 1.0036\n",
            "Step 160/249, Loss: 0.7799\n",
            "Step 170/249, Loss: 0.9219\n",
            "Step 180/249, Loss: 0.6852\n",
            "Step 190/249, Loss: 0.8022\n",
            "Step 200/249, Loss: 0.4516\n",
            "Step 210/249, Loss: 0.7638\n",
            "Step 220/249, Loss: 0.6291\n",
            "Step 230/249, Loss: 0.7331\n",
            "Step 240/249, Loss: 0.4729\n",
            "Epoch 5 Training Loss: 0.6783\n",
            "Epoch 5 Validation Loss: 2.0406\n",
            "Best model saved.\n",
            "Epoch 6/10\n",
            "Step 10/249, Loss: 0.9178\n",
            "Step 20/249, Loss: 0.6482\n",
            "Step 30/249, Loss: 0.6698\n",
            "Step 40/249, Loss: 0.6089\n",
            "Step 50/249, Loss: 0.5570\n",
            "Step 60/249, Loss: 0.6421\n",
            "Step 70/249, Loss: 0.7390\n",
            "Step 80/249, Loss: 0.3687\n",
            "Step 90/249, Loss: 0.8545\n",
            "Step 100/249, Loss: 0.7689\n",
            "Step 110/249, Loss: 0.8584\n",
            "Step 120/249, Loss: 0.6765\n",
            "Step 130/249, Loss: 0.5121\n",
            "Step 140/249, Loss: 0.9352\n",
            "Step 150/249, Loss: 0.6228\n",
            "Step 160/249, Loss: 0.6975\n",
            "Step 170/249, Loss: 0.4827\n",
            "Step 180/249, Loss: 0.6910\n",
            "Step 190/249, Loss: 0.5923\n",
            "Step 200/249, Loss: 0.6823\n",
            "Step 210/249, Loss: 0.6420\n",
            "Step 220/249, Loss: 0.7002\n",
            "Step 230/249, Loss: 0.7366\n",
            "Step 240/249, Loss: 0.5854\n",
            "Epoch 6 Training Loss: 0.6640\n",
            "Epoch 6 Validation Loss: 2.0326\n",
            "Best model saved.\n",
            "Epoch 7/10\n",
            "Step 10/249, Loss: 0.7794\n",
            "Step 20/249, Loss: 0.5703\n",
            "Step 30/249, Loss: 0.8343\n",
            "Step 40/249, Loss: 0.5979\n",
            "Step 50/249, Loss: 0.5992\n",
            "Step 60/249, Loss: 0.6665\n",
            "Step 70/249, Loss: 0.5995\n",
            "Step 80/249, Loss: 0.4541\n",
            "Step 90/249, Loss: 0.6837\n",
            "Step 100/249, Loss: 0.6514\n",
            "Step 110/249, Loss: 0.7254\n",
            "Step 120/249, Loss: 0.6565\n",
            "Step 130/249, Loss: 0.6776\n",
            "Step 140/249, Loss: 0.6201\n",
            "Step 150/249, Loss: 0.6205\n",
            "Step 160/249, Loss: 0.8999\n",
            "Step 170/249, Loss: 0.6996\n",
            "Step 180/249, Loss: 0.7428\n",
            "Step 190/249, Loss: 0.6836\n",
            "Step 200/249, Loss: 0.7395\n",
            "Step 210/249, Loss: 0.4909\n",
            "Step 220/249, Loss: 0.8537\n",
            "Step 230/249, Loss: 0.7732\n",
            "Step 240/249, Loss: 0.4827\n",
            "Epoch 7 Training Loss: 0.6531\n",
            "Epoch 7 Validation Loss: 2.0186\n",
            "Best model saved.\n",
            "Epoch 8/10\n",
            "Step 10/249, Loss: 0.7209\n",
            "Step 20/249, Loss: 0.6569\n",
            "Step 30/249, Loss: 0.6437\n",
            "Step 40/249, Loss: 0.5792\n",
            "Step 50/249, Loss: 0.6627\n",
            "Step 60/249, Loss: 0.4359\n",
            "Step 70/249, Loss: 0.4773\n",
            "Step 80/249, Loss: 0.5806\n",
            "Step 90/249, Loss: 0.7133\n",
            "Step 100/249, Loss: 0.7509\n",
            "Step 110/249, Loss: 0.4163\n",
            "Step 120/249, Loss: 0.7209\n",
            "Step 130/249, Loss: 0.8900\n",
            "Step 140/249, Loss: 0.5943\n",
            "Step 150/249, Loss: 0.7551\n",
            "Step 160/249, Loss: 0.7621\n",
            "Step 170/249, Loss: 0.4987\n",
            "Step 180/249, Loss: 1.0840\n",
            "Step 190/249, Loss: 0.6202\n",
            "Step 200/249, Loss: 0.5567\n",
            "Step 210/249, Loss: 0.4204\n",
            "Step 220/249, Loss: 0.7042\n",
            "Step 230/249, Loss: 0.5042\n",
            "Step 240/249, Loss: 0.4936\n",
            "Epoch 8 Training Loss: 0.6423\n",
            "Epoch 8 Validation Loss: 2.0218\n",
            "No improvement. Patience: 1/3\n",
            "Epoch 9/10\n",
            "Step 10/249, Loss: 0.5346\n",
            "Step 20/249, Loss: 0.6763\n",
            "Step 30/249, Loss: 0.7478\n",
            "Step 40/249, Loss: 0.5422\n",
            "Step 50/249, Loss: 0.6164\n",
            "Step 60/249, Loss: 0.6789\n",
            "Step 70/249, Loss: 0.7407\n",
            "Step 80/249, Loss: 0.6300\n",
            "Step 90/249, Loss: 0.4601\n",
            "Step 100/249, Loss: 0.8443\n",
            "Step 110/249, Loss: 0.7655\n",
            "Step 120/249, Loss: 0.6941\n",
            "Step 130/249, Loss: 0.5674\n",
            "Step 140/249, Loss: 0.6782\n",
            "Step 150/249, Loss: 0.6735\n",
            "Step 160/249, Loss: 0.4945\n",
            "Step 170/249, Loss: 0.5619\n",
            "Step 180/249, Loss: 0.5888\n",
            "Step 190/249, Loss: 0.8235\n",
            "Step 200/249, Loss: 0.5897\n",
            "Step 210/249, Loss: 0.6062\n",
            "Step 220/249, Loss: 0.6540\n",
            "Step 230/249, Loss: 0.4596\n",
            "Step 240/249, Loss: 0.4305\n",
            "Epoch 9 Training Loss: 0.6336\n",
            "Epoch 9 Validation Loss: 2.0119\n",
            "Best model saved.\n",
            "Epoch 10/10\n",
            "Step 10/249, Loss: 0.2857\n",
            "Step 20/249, Loss: 0.8598\n",
            "Step 30/249, Loss: 0.6646\n",
            "Step 40/249, Loss: 0.6200\n",
            "Step 50/249, Loss: 0.9203\n",
            "Step 60/249, Loss: 0.5797\n",
            "Step 70/249, Loss: 0.3946\n",
            "Step 80/249, Loss: 0.9078\n",
            "Step 90/249, Loss: 0.6838\n",
            "Step 100/249, Loss: 0.6231\n",
            "Step 110/249, Loss: 0.7524\n",
            "Step 120/249, Loss: 0.7183\n",
            "Step 130/249, Loss: 0.5012\n",
            "Step 140/249, Loss: 0.7098\n",
            "Step 150/249, Loss: 0.5928\n",
            "Step 160/249, Loss: 0.6327\n",
            "Step 170/249, Loss: 0.6641\n",
            "Step 180/249, Loss: 0.6454\n",
            "Step 190/249, Loss: 0.5782\n",
            "Step 200/249, Loss: 0.5421\n",
            "Step 210/249, Loss: 0.6463\n",
            "Step 220/249, Loss: 0.6730\n",
            "Step 230/249, Loss: 0.6703\n",
            "Step 240/249, Loss: 0.5259\n",
            "Epoch 10 Training Loss: 0.6228\n",
            "Epoch 10 Validation Loss: 2.0088\n",
            "Best model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Model"
      ],
      "metadata": {
        "id": "9igaPwsMIdQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150)\n",
        "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        decoded_refs = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
        "\n",
        "        predictions.extend(decoded_preds)\n",
        "        references.extend(decoded_refs)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "rouge1, rouge2, rougeL = 0, 0, 0\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1 += scores[\"rouge1\"].fmeasure\n",
        "    rouge2 += scores[\"rouge2\"].fmeasure\n",
        "    rougeL += scores[\"rougeL\"].fmeasure\n",
        "\n",
        "n = len(predictions)\n",
        "print(f\"ROUGE-1: {rouge1 / n:.4f}\")\n",
        "print(f\"ROUGE-2: {rouge2 / n:.4f}\")\n",
        "print(f\"ROUGE-L: {rougeL / n:.4f}\")\n"
      ],
      "metadata": {
        "id": "1GSCsw4DMhnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abea51b-fbe5-47ad-e90f-0ff15a4fd2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-5a2e5aa9e4ab>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1: 0.2835\n",
            "ROUGE-2: 0.1108\n",
            "ROUGE-L: 0.2078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ROUGE-1: {rouge1 * 100 / n:.4f} %\")\n",
        "print(f\"ROUGE-2: {rouge2 * 100 / n:.4f} %\")\n",
        "print(f\"ROUGE-L: {rougeL * 100 / n:.4f} %\")"
      ],
      "metadata": {
        "id": "n0x5HdLmeQnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99956a84-1e50-4683-a860-b1015d46a3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1: 28.3470 %\n",
            "ROUGE-2: 11.0757 %\n",
            "ROUGE-L: 20.7782 %\n"
          ]
        }
      ]
    }
  ]
}