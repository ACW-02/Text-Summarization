{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ec97fe1d9da4c0ebb161ecf68d85dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7498f33753d4e9ea768b0f7ed78f2b2",
              "IPY_MODEL_fb860e5f3a314051abadb2403965ab6b",
              "IPY_MODEL_82c9060fed404ecb941499bfc0764816"
            ],
            "layout": "IPY_MODEL_ad5bf1338e914d0c8f4455d5294a99a8"
          }
        },
        "d7498f33753d4e9ea768b0f7ed78f2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c1bb0f5b0d0480ab2984b6b2b14ea9b",
            "placeholder": "​",
            "style": "IPY_MODEL_3f9af5fb8537417f9dbd12d0023f2a0e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fb860e5f3a314051abadb2403965ab6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0120681df84e9bb92673feb5b8633c",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8801b7dceb894763bbf1b6bde41e4086",
            "value": 48
          }
        },
        "82c9060fed404ecb941499bfc0764816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e843ca6ed8774fea957b6c79dc49da8b",
            "placeholder": "​",
            "style": "IPY_MODEL_cda535cb74964608834ed733b991bcb6",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.74kB/s]"
          }
        },
        "ad5bf1338e914d0c8f4455d5294a99a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1bb0f5b0d0480ab2984b6b2b14ea9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9af5fb8537417f9dbd12d0023f2a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd0120681df84e9bb92673feb5b8633c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8801b7dceb894763bbf1b6bde41e4086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e843ca6ed8774fea957b6c79dc49da8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda535cb74964608834ed733b991bcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c59b22bffcc49a2881d6e4ad018e004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6582095c5f7c45d0b5d5317474626756",
              "IPY_MODEL_e6ac22695c4c4261abfa3c075d94755a",
              "IPY_MODEL_1d20887ea9264860a3c449271162acf9"
            ],
            "layout": "IPY_MODEL_88379bad5dc1401ca93fc597e52d1a12"
          }
        },
        "6582095c5f7c45d0b5d5317474626756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d131b8115c34a18a20f84c0586ee45d",
            "placeholder": "​",
            "style": "IPY_MODEL_bcbf0523996d4d5e82d7fe39130ad380",
            "value": "vocab.txt: 100%"
          }
        },
        "e6ac22695c4c4261abfa3c075d94755a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c32da57ca844c879916e4379e9e7339",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f345462dbec143a3a825b7d20bb2cc41",
            "value": 231508
          }
        },
        "1d20887ea9264860a3c449271162acf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f489e4a5118c44f7ac48c0c497aa0afb",
            "placeholder": "​",
            "style": "IPY_MODEL_f8021844a97242f4b82d5c13bf012cd6",
            "value": " 232k/232k [00:00&lt;00:00, 3.33MB/s]"
          }
        },
        "88379bad5dc1401ca93fc597e52d1a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d131b8115c34a18a20f84c0586ee45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbf0523996d4d5e82d7fe39130ad380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c32da57ca844c879916e4379e9e7339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f345462dbec143a3a825b7d20bb2cc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f489e4a5118c44f7ac48c0c497aa0afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8021844a97242f4b82d5c13bf012cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdfbb0cb2b5c4c46ab289066b2b93c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0731eb21d7b34f7da1afc0021db971ed",
              "IPY_MODEL_17160a9a88f14f4abdac11b839509aba",
              "IPY_MODEL_66f11d3cd3f749d08bfd84973f21c464"
            ],
            "layout": "IPY_MODEL_981802bcb4124613b7f17ce14c2d1eb8"
          }
        },
        "0731eb21d7b34f7da1afc0021db971ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369bcb615a984a609405bf801646d792",
            "placeholder": "​",
            "style": "IPY_MODEL_cb94e25652ef439284da5f61132b2cc2",
            "value": "tokenizer.json: 100%"
          }
        },
        "17160a9a88f14f4abdac11b839509aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc8620a7aae41b6aa735ba2ec80be72",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd71f5e108b44418ef6465e27b27a17",
            "value": 466062
          }
        },
        "66f11d3cd3f749d08bfd84973f21c464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bcf3bf63f642e3b3280c72ecb4994e",
            "placeholder": "​",
            "style": "IPY_MODEL_359812cea9ae47b79ea20e329d9d9fd9",
            "value": " 466k/466k [00:00&lt;00:00, 3.64MB/s]"
          }
        },
        "981802bcb4124613b7f17ce14c2d1eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369bcb615a984a609405bf801646d792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb94e25652ef439284da5f61132b2cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fc8620a7aae41b6aa735ba2ec80be72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd71f5e108b44418ef6465e27b27a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12bcf3bf63f642e3b3280c72ecb4994e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359812cea9ae47b79ea20e329d9d9fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd984f1cd244e7d9f87f0e8a5513a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d46ef578468e40b59024804140c588e3",
              "IPY_MODEL_d35d38315cbd423fbdb60099235ffc38",
              "IPY_MODEL_b0a6bd45e97a4d4b963bfadad67d7ce5"
            ],
            "layout": "IPY_MODEL_35889c4b6960400b911ba7c26172b35b"
          }
        },
        "d46ef578468e40b59024804140c588e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305c81f5a4c64f84a1d358a6573ff5a3",
            "placeholder": "​",
            "style": "IPY_MODEL_db71fbf191794b0fa74ddbf150830dc7",
            "value": "config.json: 100%"
          }
        },
        "d35d38315cbd423fbdb60099235ffc38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c2278c5c40b491d8a14d5ce948889eb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bebcf0295304702a4d05a40b2c99777",
            "value": 570
          }
        },
        "b0a6bd45e97a4d4b963bfadad67d7ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1b4ff7796046c7960ebb637be6effa",
            "placeholder": "​",
            "style": "IPY_MODEL_310c6d00df044fa5bd43fdb2ea15ec0d",
            "value": " 570/570 [00:00&lt;00:00, 22.2kB/s]"
          }
        },
        "35889c4b6960400b911ba7c26172b35b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305c81f5a4c64f84a1d358a6573ff5a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db71fbf191794b0fa74ddbf150830dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c2278c5c40b491d8a14d5ce948889eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bebcf0295304702a4d05a40b2c99777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d1b4ff7796046c7960ebb637be6effa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310c6d00df044fa5bd43fdb2ea15ec0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0894ba063e0f4bedace1c5015538f719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa8a28736526445d9b1ace795c0e1f4b",
              "IPY_MODEL_df422195dd2042d19f5336dad054f5d9",
              "IPY_MODEL_a7e1bcd67ab44be58787721224681376"
            ],
            "layout": "IPY_MODEL_f44e2f51817b469c95940e9ab4528d41"
          }
        },
        "fa8a28736526445d9b1ace795c0e1f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28c0482c22754035a34ad74836001aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_67ed46614f2247248f09e21f9a209a41",
            "value": "config.json: 100%"
          }
        },
        "df422195dd2042d19f5336dad054f5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984e4a0a5e514a33a7dda97e350dc38f",
            "max": 3660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_778ec912bc21461b8dc81c8cb9ae25f9",
            "value": 3660
          }
        },
        "a7e1bcd67ab44be58787721224681376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af99afbdb90743eda4dcd1e15377495b",
            "placeholder": "​",
            "style": "IPY_MODEL_68662272a8424d839c64890869d94725",
            "value": " 3.66k/3.66k [00:00&lt;00:00, 140kB/s]"
          }
        },
        "f44e2f51817b469c95940e9ab4528d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c0482c22754035a34ad74836001aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ed46614f2247248f09e21f9a209a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "984e4a0a5e514a33a7dda97e350dc38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "778ec912bc21461b8dc81c8cb9ae25f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af99afbdb90743eda4dcd1e15377495b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68662272a8424d839c64890869d94725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39cc850760764e1190a9471ff68138d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_045358e04bd04001a1ca32e5d58e8037",
              "IPY_MODEL_3eb5989448c04a688af1456f1355ac9a",
              "IPY_MODEL_f7405feae0be48dfa2324a228d8d318e"
            ],
            "layout": "IPY_MODEL_4873d0984b66455c8c5561179fbd180f"
          }
        },
        "045358e04bd04001a1ca32e5d58e8037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d96374cd0d741d1b26fbfaa9df95c38",
            "placeholder": "​",
            "style": "IPY_MODEL_07147aeeff33445c940848d4ce01e8f4",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3eb5989448c04a688af1456f1355ac9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e591241f9fa84571a66bfbc29e77c3a8",
            "max": 989691346,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff8244a4718749a9a5b4059c2e6da091",
            "value": 989691346
          }
        },
        "f7405feae0be48dfa2324a228d8d318e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37de6992f8b54fe1bd1e1ce86a5bcd00",
            "placeholder": "​",
            "style": "IPY_MODEL_f061b0b124df4140bf82e7b0c951c2f5",
            "value": " 990M/990M [00:07&lt;00:00, 166MB/s]"
          }
        },
        "4873d0984b66455c8c5561179fbd180f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d96374cd0d741d1b26fbfaa9df95c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07147aeeff33445c940848d4ce01e8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e591241f9fa84571a66bfbc29e77c3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8244a4718749a9a5b4059c2e6da091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37de6992f8b54fe1bd1e1ce86a5bcd00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f061b0b124df4140bf82e7b0c951c2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT2BERT model"
      ],
      "metadata": {
        "id": "yfpSRhQncpir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers datasets rouge-score -q"
      ],
      "metadata": {
        "id": "tFoKfR_0bod_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f487d8ea-cfd8-4899-b2d9-e127cec6eadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, EncoderDecoderModel, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "nP04UAy7bqO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohbvlB8sbzL7",
        "outputId": "c16d55a6-6051-4ebd-cbfd-a5c358632de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset as df"
      ],
      "metadata": {
        "id": "j3Lxlkx3cuXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_json(\"/content/drive/MyDrive/Binus/Sem 5/textmining/train.jsonl\", lines=True)\n",
        "# dfval = pd.read_json(\"/content/drive/MyDrive/Binus/Sem 5/textmining/dev.jsonl\", lines=True)\n",
        "# dftest = pd.read_json(\"/content/drive/MyDrive/Binus/Sem 5/textmining/test.jsonl\", lines=True)\n",
        "\n",
        "df = pd.read_json(\"/content/drive/MyDrive/sem 5/train.jsonl\", lines=True)\n",
        "dfval = pd.read_json(\"/content/drive/MyDrive/sem 5/dev.jsonl\", lines=True)\n",
        "dftest = pd.read_json(\"/content/drive/MyDrive/sem 5/test.jsonl\", lines=True)"
      ],
      "metadata": {
        "id": "b2XnTFUkb33w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "Fk9f42Odb5vk",
        "outputId": "1c7afd39-4edc-4486-c763-848c0ccf3a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Due to the success of deep learning to solvin...   \n",
              "1  [The backpropagation (BP) algorithm is often t...   \n",
              "2  [We introduce the 2-simplicial Transformer, an...   \n",
              "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
              "4  [Recent efforts on combining deep models with ...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.30188678746885, 0.37209301838831804, 0.6037...   SysEexbRb   \n",
              "1  [0.0, 0.0, 0.130434779206049, 0.14285713922902...  SygvZ209F7   \n",
              "2  [0.333333328395061, 0.8888888839111111, 0.1142...  rkecJ6VFvr   \n",
              "3  [0.066666662222222, 0.06451612466181, 0.060606...   HJJ0w--0W   \n",
              "4  [0.27777777279320903, 0.571428566658163, 0.095...   HyH9lbZAW   \n",
              "\n",
              "                                              target    ic  \\\n",
              "0  [We provide necessary and sufficient analytica...  True   \n",
              "1  [Biologically plausible learning algorithms, p...  True   \n",
              "2  [We introduce the 2-simplicial Transformer and...  True   \n",
              "3  [Accurate forecasting over very long time hori...  True   \n",
              "4  [We propose a variational message-passing algo...  True   \n",
              "\n",
              "                                               title  \n",
              "0  Critical Points of Linear Neural Networks: Ana...  \n",
              "1  Biologically-Plausible Learning Algorithms Can...  \n",
              "2             Logic and the 2-Simplicial Transformer  \n",
              "3      Long-term Forecasting using Tensor-Train RNNs  \n",
              "4  Variational Message Passing with Structured In...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a88c7d9-c0e9-4db6-bd17-38e7257225d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>ic</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Due to the success of deep learning to solvin...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.30188678746885, 0.37209301838831804, 0.6037...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>[We provide necessary and sufficient analytica...</td>\n",
              "      <td>True</td>\n",
              "      <td>Critical Points of Linear Neural Networks: Ana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.130434779206049, 0.14285713922902...</td>\n",
              "      <td>SygvZ209F7</td>\n",
              "      <td>[Biologically plausible learning algorithms, p...</td>\n",
              "      <td>True</td>\n",
              "      <td>Biologically-Plausible Learning Algorithms Can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.333333328395061, 0.8888888839111111, 0.1142...</td>\n",
              "      <td>rkecJ6VFvr</td>\n",
              "      <td>[We introduce the 2-simplicial Transformer and...</td>\n",
              "      <td>True</td>\n",
              "      <td>Logic and the 2-Simplicial Transformer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.066666662222222, 0.06451612466181, 0.060606...</td>\n",
              "      <td>HJJ0w--0W</td>\n",
              "      <td>[Accurate forecasting over very long time hori...</td>\n",
              "      <td>True</td>\n",
              "      <td>Long-term Forecasting using Tensor-Train RNNs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Recent efforts on combining deep models with ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.27777777279320903, 0.571428566658163, 0.095...</td>\n",
              "      <td>HyH9lbZAW</td>\n",
              "      <td>[We propose a variational message-passing algo...</td>\n",
              "      <td>True</td>\n",
              "      <td>Variational Message Passing with Structured In...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a88c7d9-c0e9-4db6-bd17-38e7257225d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a88c7d9-c0e9-4db6-bd17-38e7257225d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a88c7d9-c0e9-4db6-bd17-38e7257225d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfdc6fec-8c80-4d12-a2f8-885f8419151a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfdc6fec-8c80-4d12-a2f8-885f8419151a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfdc6fec-8c80-4d12-a2f8-885f8419151a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1992,\n        \"samples\": [\n          \"S1TgE7WR-\",\n          \"B1EiIsCctm\",\n          \"rknt2Be0-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1983,\n        \"samples\": [\n          \"Unsupervised Distillation of Syntactic Information from Contextualized Word Representations\",\n          \"Bridging ELBO objective and MMD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "W4iderbzcytI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "BLalG6s-SK1C",
        "outputId": "6e304597-269e-48be-ac7b-85cb67fd34c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Mixed precision training (MPT) is becoming a ...   \n",
              "1  [Many real-world problems, e.g. object detecti...   \n",
              "2  [Foveation is an important part of human visio...   \n",
              "3  [We explore the concept of co-design in the co...   \n",
              "4  [Batch Normalization (BatchNorm) has shown to ...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2                                    [0, 0, 1, 0, 0]   \n",
              "3  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.23999999580000003, 0.260869560822306, 0.199...  rJlnfaNYvB   \n",
              "1  [0.054054049086925, 0.29268292183224204, 0.974...  rJVoEiCqKQ   \n",
              "2  [0.11764705382352901, 0.11764705382352901, 0.3...  rkldVXKU8H   \n",
              "3  [0.12499999548828102, 0.488888883911111, 0.204...  BJfIVjAcKm   \n",
              "4  [0.1999999952, 0.239999995008, 0.3999999950080...  BJlEEaEFDS   \n",
              "\n",
              "                                              target     ic  \\\n",
              "0  [We devise adaptive loss scaling to improve mi...   True   \n",
              "1  [We present a novel approach for learning to p...   True   \n",
              "2  [We compare object recognition performance on ...  False   \n",
              "3  [We develop methods to train deep neural model...   True   \n",
              "4  [Investigation of how BatchNorm causes adversa...   True   \n",
              "\n",
              "                                               title  \n",
              "0  Adaptive Loss Scaling for Mixed Precision Trai...  \n",
              "1  Deep Perm-Set Net: Learn to predict sets with ...  \n",
              "2                   Foveated Downsampling Techniques  \n",
              "3  Training for Faster Adversarial Robustness Ver...  \n",
              "4  Towards an Adversarially Robust Normalization ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdbdce96-c8be-4f01-ba5f-b23fb4df1a63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>ic</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Mixed precision training (MPT) is becoming a ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.23999999580000003, 0.260869560822306, 0.199...</td>\n",
              "      <td>rJlnfaNYvB</td>\n",
              "      <td>[We devise adaptive loss scaling to improve mi...</td>\n",
              "      <td>True</td>\n",
              "      <td>Adaptive Loss Scaling for Mixed Precision Trai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Many real-world problems, e.g. object detecti...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.054054049086925, 0.29268292183224204, 0.974...</td>\n",
              "      <td>rJVoEiCqKQ</td>\n",
              "      <td>[We present a novel approach for learning to p...</td>\n",
              "      <td>True</td>\n",
              "      <td>Deep Perm-Set Net: Learn to predict sets with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Foveation is an important part of human visio...</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.11764705382352901, 0.11764705382352901, 0.3...</td>\n",
              "      <td>rkldVXKU8H</td>\n",
              "      <td>[We compare object recognition performance on ...</td>\n",
              "      <td>False</td>\n",
              "      <td>Foveated Downsampling Techniques</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We explore the concept of co-design in the co...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.12499999548828102, 0.488888883911111, 0.204...</td>\n",
              "      <td>BJfIVjAcKm</td>\n",
              "      <td>[We develop methods to train deep neural model...</td>\n",
              "      <td>True</td>\n",
              "      <td>Training for Faster Adversarial Robustness Ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Batch Normalization (BatchNorm) has shown to ...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.1999999952, 0.239999995008, 0.3999999950080...</td>\n",
              "      <td>BJlEEaEFDS</td>\n",
              "      <td>[Investigation of how BatchNorm causes adversa...</td>\n",
              "      <td>True</td>\n",
              "      <td>Towards an Adversarially Robust Normalization ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdbdce96-c8be-4f01-ba5f-b23fb4df1a63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdbdce96-c8be-4f01-ba5f-b23fb4df1a63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdbdce96-c8be-4f01-ba5f-b23fb4df1a63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e8f7eac-ff43-42c3-a555-a9856cfcefa8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e8f7eac-ff43-42c3-a555-a9856cfcefa8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e8f7eac-ff43-42c3-a555-a9856cfcefa8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfval",
              "summary": "{\n  \"name\": \"dfval\",\n  \"rows\": 619,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 619,\n        \"samples\": [\n          \"S1xD6xHKDr\",\n          \"S1l-C0NtwS\",\n          \"HJxEhREKDH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 616,\n        \"samples\": [\n          \"Efficient Inference Amortization in Graphical Models using Structured Continuous Conditional Normalizing Flows\",\n          \"Improving One-Shot NAS By Suppressing The Posterior Fading\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "pdeka2szSdZv",
        "outputId": "4b931aa0-d7d6-493c-fb91-f859f2ebd728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Incremental class learning involves sequentia...   \n",
              "1  [Multi-view learning can provide self-supervis...   \n",
              "2  [We show how discrete objects can be learnt in...   \n",
              "3  [Most recent gains in visual recognition have ...   \n",
              "4  [In recent years, deep neural networks have de...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
              "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.28571428104489804, 0.18181817681818102, 0.2...   SJ1Xmf-Rb   \n",
              "1  [0.19999999580000002, 0.0, 0.15789473418282501...  S1xzyhR9Y7   \n",
              "2  [0.9787233992575821, 0.33333332860555503, 0.41...   HJDUjKeA-   \n",
              "3  [0.11764705384083, 0.146341458655562, 0.199999...  BJgLg3R9KQ   \n",
              "4  [0.0, 0.05882352484429101, 0.270270265887509, ...  BklpOo09tQ   \n",
              "\n",
              "                                              target    ic  \\\n",
              "0  [FearNet is a memory efficient neural-network,...  True   \n",
              "1  [Multi-view learning improves unsupervised sen...  True   \n",
              "2  [We show how discrete objects can be learnt in...  True   \n",
              "3  [A large-scale dataset for training attention ...  True   \n",
              "4  [We proposed a time-efficient defense method a...  True   \n",
              "\n",
              "                                               title  \n",
              "0  FearNet: Brain-Inspired Model for Incremental ...  \n",
              "1  Improving Sentence Representations with Multi-...  \n",
              "2                       Learning objects from pixels  \n",
              "3                  Learning what and where to attend  \n",
              "4  EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEE...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-574ed752-cd08-4eef-8829-4b480ecdb183\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>ic</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Incremental class learning involves sequentia...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.28571428104489804, 0.18181817681818102, 0.2...</td>\n",
              "      <td>SJ1Xmf-Rb</td>\n",
              "      <td>[FearNet is a memory efficient neural-network,...</td>\n",
              "      <td>True</td>\n",
              "      <td>FearNet: Brain-Inspired Model for Incremental ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Multi-view learning can provide self-supervis...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "      <td>[0.19999999580000002, 0.0, 0.15789473418282501...</td>\n",
              "      <td>S1xzyhR9Y7</td>\n",
              "      <td>[Multi-view learning improves unsupervised sen...</td>\n",
              "      <td>True</td>\n",
              "      <td>Improving Sentence Representations with Multi-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We show how discrete objects can be learnt in...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.9787233992575821, 0.33333332860555503, 0.41...</td>\n",
              "      <td>HJDUjKeA-</td>\n",
              "      <td>[We show how discrete objects can be learnt in...</td>\n",
              "      <td>True</td>\n",
              "      <td>Learning objects from pixels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Most recent gains in visual recognition have ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.11764705384083, 0.146341458655562, 0.199999...</td>\n",
              "      <td>BJgLg3R9KQ</td>\n",
              "      <td>[A large-scale dataset for training attention ...</td>\n",
              "      <td>True</td>\n",
              "      <td>Learning what and where to attend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[In recent years, deep neural networks have de...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.05882352484429101, 0.270270265887509, ...</td>\n",
              "      <td>BklpOo09tQ</td>\n",
              "      <td>[We proposed a time-efficient defense method a...</td>\n",
              "      <td>True</td>\n",
              "      <td>EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEE...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-574ed752-cd08-4eef-8829-4b480ecdb183')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-574ed752-cd08-4eef-8829-4b480ecdb183 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-574ed752-cd08-4eef-8829-4b480ecdb183');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9064f382-e39a-443c-aa29-20648f62f352\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9064f382-e39a-443c-aa29-20648f62f352')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9064f382-e39a-443c-aa29-20648f62f352 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dftest",
              "summary": "{\n  \"name\": \"dftest\",\n  \"rows\": 618,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_scores\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \"BkiIkBJ0b\",\n          \"rkeMHjR9Ym\",\n          \"r1xN5oA5tm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \"Do Deep Reinforcement Learning Algorithms really Learn to Navigate?\",\n          \"Stochastic Gradient Descent Learns State Equations with Nonlinear Activations\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop source_labels, rouge_scores, paper_id, ic and title from df\n",
        "df = df.drop(['source_labels', 'rouge_scores', 'paper_id', 'ic', 'title'], axis=1)\n",
        "dfval = dfval.drop(['source_labels', 'rouge_scores', 'paper_id', 'ic', 'title'], axis=1)\n",
        "dftest = dftest.drop(['source_labels', 'rouge_scores', 'paper_id', 'ic', 'title'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GHh7RGj3b8Ih",
        "outputId": "09e8cd37-4f9e-4aa0-8111-ee11560a5d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Due to the success of deep learning to solvin...   \n",
              "1  [The backpropagation (BP) algorithm is often t...   \n",
              "2  [We introduce the 2-simplicial Transformer, an...   \n",
              "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
              "4  [Recent efforts on combining deep models with ...   \n",
              "\n",
              "                                              target  \n",
              "0  [We provide necessary and sufficient analytica...  \n",
              "1  [Biologically plausible learning algorithms, p...  \n",
              "2  [We introduce the 2-simplicial Transformer and...  \n",
              "3  [Accurate forecasting over very long time hori...  \n",
              "4  [We propose a variational message-passing algo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e4b8294-13f1-4d88-97ad-ccaba00889cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Due to the success of deep learning to solvin...</td>\n",
              "      <td>[We provide necessary and sufficient analytica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
              "      <td>[Biologically plausible learning algorithms, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
              "      <td>[We introduce the 2-simplicial Transformer and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
              "      <td>[Accurate forecasting over very long time hori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Recent efforts on combining deep models with ...</td>\n",
              "      <td>[We propose a variational message-passing algo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e4b8294-13f1-4d88-97ad-ccaba00889cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e4b8294-13f1-4d88-97ad-ccaba00889cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e4b8294-13f1-4d88-97ad-ccaba00889cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b15b7cfa-c3d1-4eec-923f-2f7624d9a493\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b15b7cfa-c3d1-4eec-923f-2f7624d9a493')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b15b7cfa-c3d1-4eec-923f-2f7624d9a493 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK0g4MWnb-wn",
        "outputId": "e22dcae2-69d5-4e3b-a767-1d274998a64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1992 entries, 0 to 1991\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  1992 non-null   object\n",
            " 1   target  1992 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r_OV9sHSl_O",
        "outputId": "d83157ce-ec7f-424c-af73-753ef551dd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 619 entries, 0 to 618\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  619 non-null    object\n",
            " 1   target  619 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQy9GeoXSxO2",
        "outputId": "aaf1b8f3-d8d3-4e21-c1b7-36611488d886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 618 entries, 0 to 617\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   source  618 non-null    object\n",
            " 1   target  618 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Cleansing"
      ],
      "metadata": {
        "id": "J7Qdqnccc4Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CYILHlucI-S",
        "outputId": "ead4cbd6-9de8-4d18-b6df-9e668705d0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleansing(df):\n",
        "    df_clean=df.astype(str).str.lower()\n",
        "    df_clean=[re.sub(r\"\\d+\",\"\",i )for i in df_clean]\n",
        "    df_clean=[re.sub(r'[^\\w]', ' ', i)for i in df_clean]\n",
        "    df_clean=[re.sub(r'\\s+',' ',i)for i in df_clean]\n",
        "    return df_clean"
      ],
      "metadata": {
        "id": "90ZXQZcFcLgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text']=cleansing(df['source'])\n",
        "df['clean_target']=cleansing(df['target'])\n",
        "dfval['clean_text']=cleansing(dfval['source'])\n",
        "dfval['clean_target']=cleansing(dfval['target'])\n",
        "dftest['clean_text']=cleansing(dftest['source'])\n",
        "dftest['clean_target']=cleansing(dftest['target'])\n",
        "\n",
        "df = df.drop(['source','target'], axis=1)\n",
        "dfval = dfval.drop(['source','target'], axis=1)\n",
        "dftest = dftest.drop(['source','target'], axis=1)"
      ],
      "metadata": {
        "id": "8tPYFsP8cM3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\"clean_text\": \"text\", \"clean_target\": \"target\"}, inplace=True)\n",
        "dfval.rename(columns={\"clean_text\": \"text\", \"clean_target\": \"target\"}, inplace=True)\n",
        "dftest.rename(columns={\"clean_text\": \"text\", \"clean_target\": \"target\"}, inplace=True)"
      ],
      "metadata": {
        "id": "8w9OyIL6cOiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LbjPg8q9cP7-",
        "outputId": "85edd4f1-ed67-4cd5-8f2f-784148cbbfaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   due to the success of deep learning to solvin...   \n",
              "1   the backpropagation bp algorithm is often tho...   \n",
              "2   we introduce the simplicial transformer an ex...   \n",
              "3   we present tensor train rnn tt rnn a novel fa...   \n",
              "4   recent efforts on combining deep models with ...   \n",
              "\n",
              "                                              target  \n",
              "0   we provide necessary and sufficient analytica...  \n",
              "1   biologically plausible learning algorithms pa...  \n",
              "2   we introduce the simplicial transformer and s...  \n",
              "3   accurate forecasting over very long time hori...  \n",
              "4   we propose a variational message passing algo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-826c9cde-97ac-4aa6-9239-8a71f7986fdb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>due to the success of deep learning to solvin...</td>\n",
              "      <td>we provide necessary and sufficient analytica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the backpropagation bp algorithm is often tho...</td>\n",
              "      <td>biologically plausible learning algorithms pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we introduce the simplicial transformer an ex...</td>\n",
              "      <td>we introduce the simplicial transformer and s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we present tensor train rnn tt rnn a novel fa...</td>\n",
              "      <td>accurate forecasting over very long time hori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recent efforts on combining deep models with ...</td>\n",
              "      <td>we propose a variational message passing algo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-826c9cde-97ac-4aa6-9239-8a71f7986fdb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-826c9cde-97ac-4aa6-9239-8a71f7986fdb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-826c9cde-97ac-4aa6-9239-8a71f7986fdb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b292e36d-8a20-4ef2-b450-d55da089e4b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b292e36d-8a20-4ef2-b450-d55da089e4b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b292e36d-8a20-4ef2-b450-d55da089e4b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1992,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1992,\n        \"samples\": [\n          \" most existing neural networks for learning graphs deal with the issue of permutation invariance by conceiving of the network as a message passing scheme where each node sums the feature vectors coming from its neighbors we argue that this imposes a limitation on their representation power and instead propose a new general architecture for representing objects consisting of a hierarchy of parts which we call covariant compositional networks ccns here covariance means that the activation of each neuron must transform in a specific way under permutations similarly to steerability in cnns we achieve covariance by making each activation transform according to a tensor representation of the permutation group and derive the corresponding tensor aggregation rules that each neuron must implement experiments show that ccns can outperform competing methods on some standard graph learning benchmarks learning on graphs has a long history in the kernels literature including approaches based on random walks bid bid bid counting subgraphs bid spectral ideas bid label propagation schemes with hashing bid neumann et al and even algebraic ideas bid many of these papers address moderate size problems in chemo and bioinformatics and the way they represent graphs is essentially fixed recently with the advent of deep learning and much larger datasets a sequence of neural network based approaches have appeared to address the same problem starting with bid in contrast to the kernels framework neural networks effectively integrate the classification or regression problem at hand with learning the graph representation itself in a single end to end system in the last few years there has been a veritable explosion in research activity in this area some of the proposed graph learning architectures bid bid bid directly seek inspiration from the type of classical cnns that are used for image recognition bid krizhevsky et al these methods involve first fixing a vertex ordering then moving a filter across vertices while doing some computation as a function of the local neighborhood to generate a representation this process is then repeated multiple times like in classical cnns to build a deep graph representation other notable works on graph neural networks include bid bid bid bid very recently bid showed that many of these approaches can be seen to be specific instances of a general message passing formalism and coined the term message passing neural networks mpnns to refer to them collectively while mpnns have been very successful in applications and are an active field of research they differ from classical cnns in a fundamental way the internal feature representations in cnns are equivariant to such transformations of the inputs as translation and rotations bid the internal representations in mpnns are fully invariant this is a direct result of the fact that mpnns deal with the permutation invariance issue in graphs simply by summing the messages coming from each neighbor in this paper we argue that this is a serious limitation that restricts the representation power of mpnns mpnns are ultimately compositional part based models that build up the representation of the graph from the representations of a hierarchy of subgraphs to address the covariance issue we study the covariance behavior of such networks in general introducing a new general class of neural network architectures which we call compositional networks comp nets one advantage of this generalization is that instead of focusing attention on the mechanics of how information propagates from node to node it emphasizes the connection to convolutional networks in particular it shows that what is missing from mpnns is essentially the analog of steerability steerability implies that the activations feature vectors at a given neuron must transform according to a specific representation in the algebraic sense of the symmetry group of its receptive field in our case the group of permutations s m in this paper we only consider the defining representation and its tensor products leading to first second third etc order tensor activations we derive the general form of covariant tensor propagation in comp nets and find that each channel in the network corresponds to a specific way of contracting a higher order tensor to a lower order one note that here by tensor activations we mean not just that each activation is expressed as a multidimensional array of numbers as the word is usually used in the neural networks literature but also that it transforms in a specific way under permutations which is a more stringent criterion the parameters of our covariant comp nets are the entries of the mixing matrix that prescribe how these channels communicate with each other at each node our experiments show that this new architecture can beat scalar message passing neural networks on several standard datasets on the subsampled hcep dataset ccn outperforms all other methods by a very large margin for the graph kernels datasets svm with the weisfeiler lehman kernels achieve the highest accuracy on nci and nci while ccn wins on mutag and ptc perhaps this poor performance is to be expected since the datasets are small and neural network approaches usually require tens of thousands of training examples at minimum to be effective indeed neural graph fingerprints and pscn also perform poorly compared to the weisfeiler lehman kernels in the qm experiments ccn beats the three other algorithms in both mean absolute error and root mean squared error it should be noted that bid obtained stronger results on qm but we cannot properly compare our results with theirs because our experiments only use the adjacency matrices and atom labels of each node while theirs includes comprehensive chemical features that better inform the target quantum properties we have presented a general framework called covariant compositional networks ccns for constructing covariant graph neural networks which encompasses other message passing approaches as special cases but takes a more general and principled approach to ensuring covariance with respect to permutations experimental results on several benchmark datasets show that ccns can outperform other state of the art algorithms clearly true since f a f a \\u03be a now assume that it is true for all nodes with height up to h for any node n a with h a h f a \\u03c6 f c f c f c k where each of the children c c k are of height at most h therefore f a \\u03c6 f c f c f c k \\u03c6 f c f c f c k f a thus f a f a for every node in g the proposition follows by \\u03c6 g f r f r \\u03c6 g proof of proposition let g g n and n be as in definition as in definition for each node neuron n i in n there is a node n j in n such that their receptive fields are equivalent up to permutation that is if p i m then p j m and there is a permutation \\u03c0 s m such that if p i e p e pm and p j e q e qm then e q \\u03c0 a e pa by covariance then f j r \\u03c0 f i now let g be a third equivalent object and n the corresponding comp net n must also have a node n k that corresponds to n i and n j in particular letting its receptive field be p k e r e rm there is a permutation \\u03c3 s m for which e r \\u03c3 b e q b therefore f k r \\u03c3 f j at the same time n k is also in correspondence with n i in particular letting \\u03c4 \\u03c3\\u03c0 which corresponds to first applying the permutation \\u03c0 then applying \\u03c3 e r \\u03c4 a e pa and therefore f k r \\u03c4 f i hence the r \\u03c0 maps must satisfy case follows directly from case finally if a a u are k th order p tensors and c j \\u03b1 j a j then displayform so c is a k th order p tensor proof of proposition under the action of a permutation \\u03c0 s m on p b \\u03c7 dropping the a b superscipt transforms to \\u03c7 where \\u03c7 i j \\u03c7 \\u03c0 i j however this can also be written as displayform therefore f i i k transforms to displayform so f is a p tensor proof of proposition by proposition under the action of any permutation \\u03c0 each of the f pj slices of f transforms as displayform at the same time \\u03c0 also permutes the slices amongst each other according to displayform so f is a k th order p tensor proof of proposition under any permutation \\u03c0 s m of p i a p i transforms to a p i where a p i \\u03c0 a \\u03c0 b a pi a b therefore a pi is a second order p tensor by the first case of proposition f a pi is then a k th order p tensor \",\n          \" generative models with both discrete and continuous latent variables are highly motivated by the structure of many real world data sets they present however subtleties in training often manifesting in the discrete latent variable not being leveraged in this paper we show why such models struggle to train using traditional log likelihood maximization and that they are amenable to training using the optimal transport framework of wasserstein autoencoders we find our discrete latent variable to be fully leveraged by the model when trained without any modifications to the objective function or significant fine tuning our model generates comparable samples to other approaches while using relatively simple neural networks since the discrete latent variable carries much of the descriptive burden furthermore the discrete latent provides significant control over generation unsupervised learning using generative latent variable models provides a powerful and general approach to learning the underlying low dimensional structure from large unlabeled datasets perhaps the two most common techniques for training such models are variational autoencoders vaes and generative adversarial networks gans bid both have advantages and disadvantages vaes provide a meaningful lower bound on the log likelihood that is stable under training as well as an encoding distribution from the data into the latent however they generate blurry samples due to their objective being unable to handle deterministic decoders and tractability requiring simple priors bid on the other hand gans naturally enable deterministic generative models with sharply defined samples but their training procedure is less stable a relatively new approach to training generative models has emerged based on minimizing the optimal transport ot distance bid between the generative model distribution and that of the data the ot approach provides a general framework for training generative models which promises some of the best of both gans and vaes though interesting first results have been given in bid the ot approach to generative modelling is still nascent our contributions are twofold we seek to improve generative modelling capabilities with discrete and continuous latent variables but importantly we seek also to establish that training generative models with ot can be significantly more effective than the traditional vae approach discrete latent variable models are critical to the endeavor of unsupervised learning because of the ubiquity of discreteness in the natural world and hence in the datasets that describe it however they are harder to train than their continuous counterparts this has been tackled in a number of ways e g directly mitigating high variance discrete samples bid bid parametrizing discrete distributions using continuous ones bid bid bid deliberate model design leveraging conjugacy however even in the simple case where the number of mixtures is small enough that monte carlo sampling from the discrete latent is avoidable training can still be problematic for example in bid a gaussian mixture latent variable model gm lvm was studied and the authors were unable to train their model on mnist using variational inference without substantially modifying the vae objective what appears to happen is that the model quickly learns to hack the vae objective function by collapsing the discrete latent variational distribution this problem only occurs in the unsupervised setting as are able to learn the discrete latent in the semi supervised version of the same problem once they have labeled samples for the discrete latent to latch onto this is discussed in more detail in section the ot approach to training generative models in particular the wasserstein distance discussed in section induces a weaker topology on the space of distributions enabling easier convergence of distributions than in the case of vaes bid thus one might conjecture that the ot approach would enable easier training of gm lvms than the vae approach we provide evidence that this is indeed the case showing that gm lvms can be trained in the unsupervised setting on mnist and motivating further the value of the ot approach to generative modelling we studied an unsupervised generative model with a mixture of gaussians latent variable structure well suited to data containing discrete classes of objects with continuous variation within each class we showed that such a simple and critical class of models fails to train using the vae framework in the sense that it immediately learns to discard its discrete latent structure we further exposed the root cause of this phenomenon with empirical results we then put to the test the abstract mathematical claim that the wasserstein distance induces a weaker topology on the space of distributions by attempting to train the same mixture of gaussians model in the wae framework we found the wasserstein objective is successful at training this model to leverage its discrete continuous latent structure fully we provided promising results on mnist and demonstrated the additional control available to a highly structured model with both discrete and continuous latent variables we hope this motivates further study of the exciting but nascent field of optimal transport in generative modeling \",\n          \" one of the distinguishing aspects of human language is its compositionality which allows us to describe complex environments with limited vocabulary previously it has been shown that neural network agents can learn to communicate in a highly structured possibly compositional language based on disentangled input e g hand engineered features humans however do not learn to communicate based on well summarized features in this work we train neural agents to simultaneously develop visual perception from raw image pixels and learn to communicate with a sequence of discrete symbols the agents play an image description game where the image contains factors such as colors and shapes we train the agents using the obverter technique where an agent introspects to generate messages that maximize its own understanding through qualitative analysis visualization and a zero shot test we show that the agents can develop out of raw image pixels a language with compositional properties given a proper pressure from the environment one of the key requirements for artificial general intelligence agi to thrive in the real world is its ability to communicate with humans in natural language natural language processing nlp has been an active field of research for a long time and the introduction of deep learning bid enabled great progress in nlp tasks such as translation image captioning text generation and visual question answering vinyals et al bid bid serban et al bid bid however training machines in a supervised manner with a large dataset has its limits when it comes to communication supervised methods are effective for capturing statistical associations between discrete symbols i e words letters the essence of communication is more than just predicting the most likely word to come next it is a means to coordinate with others and potentially achieve a common goal bid bid wittgenstein an alternative path to teaching machines the art of communication is to give them a specific task and encourage them to learn how to communicate on their own this approach will encourage the agents to use languages grounded to task related entities as well as communicate with other agents which is one of the ways humans learn to communicate bid recently there have been several notable works that demonstrated the emergence of communication between neural network agents even though each work produced very interesting results of its own in all cases communication was either achieved with a single discrete symbol as opposed to a sequence of discrete symbols bid bid or via a continuous value sukhbaatar et al bid not only is human communication un differentiable but also using a single discrete symbol is quite far from natural language communication one of the key features of human language is its compositional nature the meaning of a complex expression is determined by its structure and the meanings of its constituents bid more recently bid and bid trained the agents to communicate in grounded compositional language in both studies however inputs given to the agents were hand engineered features disentangled input rather than raw perceptual signals that we receive as humans in this work we train neural agents to simultaneously develop visual perception from raw image pixels and learn to communicate with a sequence of discrete symbols unlike previous works our setup poses greater challenges to the agents since visual understanding and discrete communication have to be induced from scratch in parallel we place the agents in a two person image description game where images contain objects of various color and shape inspired by the pioneering work of bid we employ a communication philosophy named obverter to train the agents having its root in the theory of mind premack woodruff and human language development bid the obverter technique motivates an agent to search over messages and generate the ones that maximize their own understanding the contribution of our work can be summarized as follows we train artificial agents to learn to disentangle raw image pixels and communicate in compositional language at the same time we describe how the obverter technique a differentiable learning algorithm for discrete communication could be employed in a communication game with raw visual input we visualize how the agents are perceiving the images and show that they learn to disentangle color and shape without any explicit supervision other than the communication one experiment results suggest that the agents could develop out of raw image input a language with compositional properties given a proper pressure from the environment i e the image description game finally while our exposition follows a multi agent perspective it is also possible to interpret our results in the single agent setting we are effectively learning a neural network that is able to learn disentangled compositional representations of visual scenes without any supervision subject to the constraints imposed by their environment our agents learn disentangled concepts and how to compose these to form new concepts this is an important milestone in the path to agi in this work we used the obverter technique to train neural network agents to communicate in a two person image description game through qualitative analysis visualization and the zero shot test we have shown that even though the agents receive raw perception in the form of image pixels under the right environment pressures the emerged language had properties consistent with the ones found in compositional languages as an evaluation strategy we followed previous works and focused on assessing the necessary conditions of compositional languages however the exact definition of compositional language is still somewhat debatable and to the best of our knowledge there is no reliable way to mathematically quantify the degree of compositionality of an arbitrary language therefore in order to encourage active research and discussion among researchers in this domain we propose for future work a quantitatively measurable definition of compositionality we believe compositionality of a language is not binary e g language a is compositional not compositional but a spectrum for example human language has some aspects that are compositional e g syntactic constructions most morphological combinations and some that are not e g irregular verb tenses in english character level word composition it is also important to clearly define grounded language and compositional language if one agent says abc eat red apple and another says cba apple red eat and they both understand each other are they speaking compositional language we believe such questions should be asked and addressed to shape the definition of compositionality in addition to the definition evaluation of compositional languages there are numerous directions of future work observing the emergence of a compositional language among more than two agents is an apparent next step designing an environment to motivate the agents to disentangle more than two factors is also an interesting direction training agents to consider the context i e pragmatics such as giving each agent several images instead of one is another exciting future work a emergence of grammar bid in bid the author successfully trained neural agents to develop a structured i e grammatical language using disentangled meaning vectors as the input using subject vectors and predicate vectors all represented as explicit binary vectors total meaning vectors could be composed tab each digit in the subject vector a serves a clear role respectively representing speaker sp hearer hr other ot and plural pl the predicate vector values on the other hand are randomly chosen so that each predicate vector will have three s and three s the combination of ten subject vectors and ten predicate vectors allows meaning vectors the author used twenty neural agents for the experiment each agent was implemented with the vanilla recurrent neural networks rnn where the hidden vector h s size was same as the size of the meaning vector m in order to treat h as the agent s understanding of m in each training round a single learner i e listener and ten teachers i e speaker were randomly chosen each teacher given all m s in random order generates a message s for each m and sends it to the learner the messages are generated using the obverter techinque which is described in algorithm the learner is trained to minimize the mean squared error mse between h after consuming the s and m after the learner has learned from all ten teachers the next round begins repeating the process until the error goes below some threshold algorithm message generation process used in bid displayform append i to s displayform terminate when the training was complete the author was able to find strong patterns in the messages used by the agents table note that the messages using predicates tired scared sick and happy especially follow a very clear pattern batali also conducted a zero shot test where the agents were trained without the diagonal elements in table and tested with all meaning vectors the agents were able to successfully communicate even when held out meaning vectors were used but the table top messages used by a majority of the population for each of the given meanings bottom a potential analysis of the system in terms of a root plus modifications italic symbols are used to specify predicates and roman symbols are used to specify subjects messages in parentheses cannot be made to fit into this analysis messages used for the held out meaning vectors did not show as strong compositional patterns as the non zero shot case \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          \" in this paper we propose a three dimensional regularization based pruning method to accelerate the d cnn \",\n          \" a graph neural network able to automatically learn and leverage a dynamic interactive graph structure \",\n          \" we train neural network agents to develop a language with compositional properties from raw pixel input \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO2W4qN4cSD-",
        "outputId": "89033ba3-d853-49b0-cb47-1039c70a080d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1992 entries, 0 to 1991\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1992 non-null   object\n",
            " 1   target  1992 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ehaRmSYlTTDH",
        "outputId": "e2c5ac70-c896-4918-da4f-a5962ad798e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   mixed precision training mpt is becoming a pr...   \n",
              "1   many real world problems e g object detection...   \n",
              "2   foveation is an important part of human visio...   \n",
              "3   we explore the concept of co design in the co...   \n",
              "4   batch normalization batchnorm has shown to be...   \n",
              "\n",
              "                                              target  \n",
              "0   we devise adaptive loss scaling to improve mi...  \n",
              "1   we present a novel approach for learning to p...  \n",
              "2   we compare object recognition performance on ...  \n",
              "3   we develop methods to train deep neural model...  \n",
              "4   investigation of how batchnorm causes adversa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b1caa46-85e6-46c0-bc16-94bfb79e476b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mixed precision training mpt is becoming a pr...</td>\n",
              "      <td>we devise adaptive loss scaling to improve mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>many real world problems e g object detection...</td>\n",
              "      <td>we present a novel approach for learning to p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>foveation is an important part of human visio...</td>\n",
              "      <td>we compare object recognition performance on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we explore the concept of co design in the co...</td>\n",
              "      <td>we develop methods to train deep neural model...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>batch normalization batchnorm has shown to be...</td>\n",
              "      <td>investigation of how batchnorm causes adversa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b1caa46-85e6-46c0-bc16-94bfb79e476b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b1caa46-85e6-46c0-bc16-94bfb79e476b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b1caa46-85e6-46c0-bc16-94bfb79e476b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80af8020-2e7e-4c03-ab2e-c8c87cca1854\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80af8020-2e7e-4c03-ab2e-c8c87cca1854')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80af8020-2e7e-4c03-ab2e-c8c87cca1854 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfval",
              "summary": "{\n  \"name\": \"dfval\",\n  \"rows\": 619,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \" the interpretability of neural networks has become crucial for their applications in real world with respect to the reliability and trustworthiness existing explanation generation methods usually provide important features by scoring their individual contributions to the model prediction and ignore the interactions between features which eventually provide a bag of words representation as explanation in natural language processing this type of explanations is challenging for human user to understand the meaning of an explanation and draw the connection between explanation and model prediction especially for long texts in this work we focus on detecting the interactions between features and propose a novel approach to build a hierarchy of explanations based on feature interactions the proposed method is evaluated with three neural classifiers lstm cnn and bert on two benchmark text classification datasets the generated explanations are assessed by both automatic evaluation measurements and human evaluators experiments show the effectiveness of the proposed method in providing explanations that are both faithful to models and understandable to humans deep neural networks have become a significant component in natural language processing nlp achieving state of the art performance in various nlp tasks such as text classification kim question answering rajpurkar et al and machine translation bahdanau et al however the lack of understanding on their decision making leads them to be characterized as black box models and increases the risk of applying them in real world applications lipton producing interpretable decisions has been a critical factor on whether people will trust and use the neural network models ribeiro et al most of existing work on local explanation generation for nlp focuses on producing word level explanations ribeiro et al lei et al plumb et al where a local explanation consists of a set of words extracted from the original text figure presents an example sentence with its sentiment prediction and corresponding word level explanation generated by lime ribeiro et al although the lime explanation captures a negative sentiment word waste it presents the explanation in a bag of words format without resorting to the original text it is difficult for us to understand the contribution of word a and of as both of them have no sentiment polarity the situation will become even more serious when this type of explanations are extracted from longer texts in this work we present a novel method to construct hierarchical explanations of a model prediction by capturing the interaction between features ultimately our method is able to produce a hierarchical structure as illustrated in figure produced by the proposed method this example provides a comprehensive picture of how different granularity of features interacting with each other for model prediction with the hierarchical structure this example tells us how the words and phrases are combined and what are the contributions of words and phrases to the final prediction for example the contribution of the phrase of good is dominated by the word waste which eventually leads to the right prediction figure a negative movie review a waste of good performance with a lime explanation and a hierarchical explanation where the color of each block represents the importance of the corresponding word phrase with respect to the model prediction to capture feature interactions we adopt the interacted shapley value lundberg et al an extension of shapley value shapley from cooperative game theory to measure the interactions between features based on the interaction scores we propose a top down method called intershapley to segment a text recursively into phrases and then words eventually the proposed method is evaluated on text classification tasks with three typical neural network models long short term memory networks hochreiter schmidhuber lstm and convolutional neural networks kim cnn and a state of the art model bert devlin et al on some benchmark datasets the comparison of our method is against several competitive baselines from prior work on explanation generation including leave one out li et al contextual decomposition cd murdoch et al and its hierarchical extension acd singh et al l and c shapley chen et al and lime ribeiro et al our contribution of this work is three fold we propose an effective method to calculate feature importance and extend the shapley value to measure feature interactions we design a top down segmentation algorithm to build hierarchical interpretations based on feature interactions we compare the proposed method with several competitive baselines via both automatic and human evaluations and show the intershapley method outperforms the existing methods on both wordand phrase level explanations \",\n          \" learning multilingual representations of text has proven a successful method for many cross lingual transfer learning tasks there are two main paradigms for learning such representations alignment which maps different independently trained monolingual representations into a shared space and joint training which directly learns unified multilingual representations using monolingual and cross lingual objectives jointly in this paper we first conduct direct comparisons of representations learned using both of these methods across diverse cross lingual tasks our empirical results reveal a set of pros and cons for both methods and show that the relative performance of alignment versus joint training is task dependent stemming from this analysis we propose a simple and novel framework that combines these two previously mutually exclusive approaches extensive experiments on various tasks demonstrate that our proposed framework alleviates limitations of both approaches and outperforms existing methods on the muse bilingual lexicon induction bli benchmark we further show that our proposed framework can generalize to contextualized representations and achieves state of the art results on the conll cross lingual ner benchmark continuous word representations mikolov et al a pennington et al bojanowski et al have become ubiquitous across a wide range of nlp tasks in particular methods for crosslingual word embeddings clwe have proven a powerful tool for cross lingual transfer for downstream tasks such as text classification klementiev et al a dependency parsing ahmad et al named entity recognition ner xie et al chen et al natural language inference language modeling adams et al and machine translation mt zou et al artetxe et al b the goal of these clwe methods is to learn embeddings in a shared vector space for two or more languages there are two main paradigms for learning clwe cross lingual alignment and joint training the most successful approach has been the cross lingual embedding alignment method mikolov et al b which relies on the assumption that monolingually trained continuous word embedding spaces share similar structure across different languages the underlying idea is to first independently train embeddings in different languages using monolingual corpora alone and then learn a mapping to align them to a shared vector space such a mapping can be trained in a supervised fashion using parallel resources such as bilingual lexicons xing et al smith et al joulin et al b jawanpuria et al or even in an unsupervised manner based on distribution matching zhang et al a artetxe et al a zhou et al recently it has been shown that alignment methods can also be effectively applied to contextualized word representations schuster et al aldarmaki diab another successful line of research for clwe considers joint training methods which optimize a monolingual objective predicting the context of a word in a monolingual corpus along with either a code will be released on publication in this paper supervision refers to that provided by a parallel corpus or bilingual dictionaries hard or soft cross lingual constraint similar to alignment methods some early works rely on bilingual dictionaries ammar et al duong et al or parallel corpora luong et al for direct supervision more recently a seemingly naive unsupervised joint training approach has received growing attention due to its simplicity and effectiveness in particular reports that simply training embeddings on concatenated monolingual corpora of two related languages using a shared vocabulary without any cross lingual resources is able to produce higher accuracy than the more sophisticated alignment methods on unsupervised mt tasks besides for contextualized representations unsupervised multilingual language model pretraining using a shared vocabulary has produced state of the art results on multiple benchmarks devlin et al artetxe schwenk lample conneau despite a large amount of research on both alignment and joint training previous work has neither performed a systematic comparison between the two analyzed their pros and cons nor elucidated when we may prefer one method over the other particularly it s natural to ask does the phenomenon reported in extend to other cross lingual tasks can we employ alignment methods to further improve their proposed unsupervised joint training if so how would such a framework compare to supervised joint training methods that exploit equivalent resources and lastly can this framework generalize to contextualized representations in this work we attempt to address these questions specifically we first evaluate and compare alignment versus joint training methods across three diverse tasks bli cross lingual ner and unsupervised mt we seek to characterize the conditions under which one approach outperforms the other and glean insight on the reasons behind these differences based on our analysis we further propose a simple novel and highly generic framework that uses unsupervised joint training as initialization and alignment as refinement to combine both paradigms our experiments demonstrate that our framework improves over both alignment and joint training baselines and outperforms existing methods on the muse bli benchmark moreover we show that our framework can generalize to contextualized representations producing state of the art results on the conll cross lingual ner benchmark to the best of our knowledge this is the first framework that combines previously mutually exclusive alignment and joint training methods in this paper we systematically compare the alignment and joint training methods for clwe we point out that the nature of each category of methods leads to certain strengths and limitations the empirical experiments on extensive benchmark datasets and various nlp tasks verified our analysis to further improve the state of art of clwe we propose a simple hybrid framework which combines the strength from both worlds and achieves significantly better performance in the bli mt and ner tasks our work opens a promising new direction that combines two previously exclusive lines of research for future work an interesting direction is to find a more optimal word sharing strategy \",\n          \" we study the convergence of gradient descent gd and stochastic gradient descent sgd for training l hidden layer linear residual networks resnets we prove that for training deep residual networks with certain linear transformations at input and output layers which are fixed throughout training both gd and sgd with zero initialization on all hidden weights can converge to the global minimum of the training loss moreover when specializing to appropriate gaussian random linear transformations gd and sgd provably optimize wide enough deep linear resnets compared with the global convergence result of gd for training standard deep linear networks citep duwidth our condition on the neural network width is sharper by a factor of o kappa l where kappa denotes the condition number of the covariance matrix of the training data in addition for the first time we establish the global convergence of sgd for training deep linear resnets and prove a linear convergence rate when the global minimum is despite the remarkable power of deep neural networks dnns trained using stochastic gradient descent sgd in many machine learning applications theoretical understanding of the properties of this algorithm or even plain gradient descent gd remains limited many key properties of the learning process for such systems are also present in the idealized case of deep linear networks for example a the objective function is not convex b errors back propagate and c there is potential for exploding and vanishing gradients in addition to enabling study of systems with these properties in a relatively simple setting analysis of deep linear networks also facilitates the scientific understanding of deep learning because using linear networks can control for the effect of architecture choices on the expressiveness of networks arora et al du hu for these reasons deep linear networks have received extensive attention in recent years one important line of theoretical investigation of deep linear networks concerns optimization landscape analysis kawaguchi hardt ma freeman bruna lu kawaguchi yun et al zhou liang where major findings include that any critical point of a deep linear network with square loss function is either a global minimum or a saddle point and identifying conditions on the weight matrices that exclude saddle points beyond landscape analysis another research direction aims to establish convergence guarantees for optimization algorithms e g gd sgd for training deep linear networks arora et al studied the trajectory of gradient flow and showed that depth can help accelerate the optimization of deep linear networks ji telgarsky gunasekar et al investigated the implicit bias of gd for training deep linear networks and deep linear convolutional networks respectively more recently bartlett et al arora et al a shamir du hu analyzed the optimization trajectory of gd for training deep linear networks and proved global convergence rates under certain assumptions on the training data initialization and neural network structure inspired by the great empirical success of residual networks resnets hardt ma considered identity parameterizations in deep linear networks i e parameterizing each layer s weight matrix as i w which leads to the so called deep linear resnets in particular hardt ma established the existence of small norm solutions for deep residual networks with sufficiently large depth l and proved that there are no critical points other than the global minimum when the maximum spectral norm among all weight matrices is smaller than op lq motivated by this intriguing finding bartlett et al studied the convergence rate of gd for training deep linear networks with identity initialization which is equivalent to zero initialization in deep linear resnets they assumed whitened data and showed that gd can converge to the global minimum if i the training loss at the initialization is very close to optimal or ii the regression matrix \\u03c6 is symmetric and positive definite in fact they proved that when \\u03c6 is symmetric and has negative eigenvalues gd for linear resnets with zero initialization does not converge arora et al a showed that gd converges under substantially weaker conditions which can be satisfied by random initialization schemes the convergence theory of stochastic gradient descent for training deep linear resnets is largely missing it remains unclear under which conditions sgd can be guaranteed to find the global minimum in this paper we establish the global convergence of both gd and sgd for training deep linear resnets without any condition on the training data more specifically we consider the training of l hidden layer deep linear resnets with fixed linear transformations at input and output layers we prove that under certain conditions on the input and output linear transformations gd and sgd can converge to the global minimum of the training loss function moreover when specializing to appropriate gaussian random linear transformations we show that as long as the neural network is wide enough both gd and sgd with zero initialization on all hidden weights can find the global minimum there are two main ingredients of our proof i establishing restricted gradient bounds and a smoothness property and ii proving that these properties hold along the optimization trajectory and further lead to global convergence we point out the second aspect is challenging especially for sgd due to the uncertainty of its optimization trajectory caused by stochastic gradients we summarize our main contributions as follows we prove the global convergence of gd and sgd for training deep linear resnets specifically we derive a generic condition on the input and output linear transformations under which both gd and sgd with zero initialization on all hidden weights can find global minima based on this condition one can design a variety of input and output transformations for training deep linear resnets when applying appropriate gaussian random linear transformations we show that as long as the neural network width satisfies m \\u03c9pkr\\u03ba q with high probability gd can converge to the global minimum up to an error within op\\u03ba logp qq iterations where k r are the output dimension and the rank of training data matrix x respectively and \\u03ba x \\u03c3 r pxq denotes the condition number of the covariance matrix of the training data compared with previous convergence results for training deep linear networks from du hu our condition on the neural network width is independent of the neural network depth l and is strictly better by a factor of opl\\u03baq using the same gaussian random linear transformations we also establish the convergence guarantee of sgd for training deep linear resnets we show that if the neural network width satisfies m r \\u03c9 kr\\u03ba log p q n b with constant probability sgd can converge to the global minimum up to an error within r o \\u03ba logp q n b iterations where n is the training sample size and b is the minibatch size of stochastic gradient this is the first global convergence rate of sgd for training deep linear networks moreover when the global minimum of the training loss is we prove that sgd can further achieve linear rate of global convergence and the condition on the neural network width does not depend on the target error as alluded to above we analyze networks with d inputs k outputs and m \\u011b maxtd ku nodes in each hidden layer linear transformations that are fixed throughout training map the inputs to the first hidden layer and the last hidden layer to the outputs we prove that our bounds hold with high probability when these input and output transformations are randomly generated by gaussian distributions if instead the input transformation simply copies the inputs onto the first d components of the first hidden layer and the output transformation takes the first k components of the last hidden layer then our analysis does not provide a guarantee there is a good reason for this a slight modification of a lower bound argument from bartlett et al demonstrates that gd may fail to converge in this case however we describe a similarly simple deterministic choice of input and output transformations such that wide enough networks always converge the resulting condition on the network width is weaker than that for gaussian random transformations and thus improves on the corresponding convergence guarantee for linear networks which in addition to requiring wider networks only hold with high probability for random transformations in this section we will discuss several different choices of linear transformations at input and output layers and their effects to the convergence performance for simplicity we will only consider the condition for gd as we stated in subsection gd converges if the input and output weight matrices a and b then it is interesting to figure out what kind of choice of a and b can satisfy this condition in proposition we showed that gaussian random transformations i e each entry of a and b is generated from certain gaussian distribution satisfy this condition with high probability so that gd converges here we will discuss the following two other transformations identity transformations we first consider the transformations that a ri d\\u02c6d d\\u02c6pm dq s j and b a m k ri k\\u02c6k k\\u02c6pm kq s which is equivalent to the setting in bartlett et al when m k d then it is clear that \\u03c3 min pbq \\u03c3 max pbq a m k and \\u03c3 min paq \\u03c3 max paq now let us consider lpw pq q by our choices of b and a and zero initialization on weight matrices in hidden layers in the case that d k we have could be as big as f for example when x and y are orthogonal then plugging these results into the condition on a and b becomes where the second inequality is due to the fact that lpw q \\u010f y f then it is clear if x f \\u011b c the above inequality cannot be satisfied for any choice of m since it will be cancelled out on both sides of the inequality therefore in such cases our bound does not guarantee that gd achieves global convergence thus it is consistent with the non convergence results in bartlett et al note that replacing the scaling factor a m k in the definition of b with any other function of d k and m would not help gaussian random initialization on hidden weights where the input and output weights are generated by random initialization and remain fixed throughout the training modified identity transformations in fact we show that a different type of identity transformations of a and b can satisfy the condition here we provide one such example assuming m \\u011b d k we can construct two sets s s \\u0103 rms satisfying then we construct matrices a and b as follows where \\u03b1 is a parameter which will be specified later in this way it can be verified that ba \\u03c3 min paq \\u03c3 max paq and \\u03c3 min pbq \\u03c3 max pbq \\u03b1 thus it is clear that the initial training loss satisfies lpw pq q y f then plugging these results into the condition on a and b can be rewritten as the r h s of the above inequality does not depend on \\u03b1 which implies that we can choose sufficiently large \\u03b1 to make this inequality hold thus gd can be guaranteed to achieve the global convergence moreover it is worth noting that using modified identity transformation a neural network with m d k suffices to guarantee the global convergence of gd we further remark that similar analysis can be extended to sgd in this paper we proved the global convergence of gd and sgd for training deep linear resnets with square loss more specifically we considered fixed linear transformations at both input and output layers and proved that under certain conditions on the transformations gd and sgd with zero initialization on all hidden weights can converge to the global minimum in addition we further proved that when specializing to appropriate gaussian random linear transformations gd and sgd can converge as long as the neural network is wide enough when w is staying inside a certain region its proof is in section b lemma a let \\u03c4 l then for any weight matrices satisfying max lprls w l \\u010f it holds that in addition the stochastic gradient g l in algorithm satisfies where b is the minibatch size the gradient lower bound can be also interpreted as the polyak \\u0142ojasiewicz condition which is essential to the linear convergence rate the gradient upper bound is crucial to bound the trajectory length since this lemma requires that max lprls w l \\u010f the following lemma proves the smoothness property of the training loss function lpwq when w is staying inside a certain region its proof is in section b lemma a let \\u03c4 l then for any two collections of weight matrices denoted by based on these two lemmas we are able to complete the proof of all theorems which are provided as follows \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 619,\n        \"samples\": [\n          \" a novel approach to construct hierarchical explanations for text classification by detecting feature interactions a novel method for providing explanations for predicitions made by text classifiers that outperforms baselines on word level importance scores and a new metric cohesion loss to evaluate span level importance an interpretation method based on feature interactions and feature importance score as compared to independent feature contributions \",\n          \" we conduct a comparative study of cross lingual alignment vs joint training methods and unify these two previously exclusive paradigms in a new framework this paper compares approaches to bilingual lexicon induction and shows which method performs better on lexicon induction and ner and mt tasks \",\n          \" under certain condition on the input and output linear transformations both gd and sgd can achieve global convergence for training deep linear resnets the authors study the convergence of gradient descent in training deep linear residual networks and establish a global convergence of gd sgd and linear convergence rates of sg sgd study of convergence properties of gd and sgd on deep linear resnets and proof that under certain conditions on the input and output transformations and with zero initialization gd and sgd converges to global minima \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfval.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYlGZwAcTVOB",
        "outputId": "307d16a3-ffd0-45b2-c40b-7d55a9b85a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 619 entries, 0 to 618\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    619 non-null    object\n",
            " 1   target  619 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AfdDjXLGTYtp",
        "outputId": "c9d79431-6bbc-4b5a-d4bc-118172bfa103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   incremental class learning involves sequentia...   \n",
              "1   multi view learning can provide self supervis...   \n",
              "2   we show how discrete objects can be learnt in...   \n",
              "3   most recent gains in visual recognition have ...   \n",
              "4   in recent years deep neural networks have dem...   \n",
              "\n",
              "                                              target  \n",
              "0   fearnet is a memory efficient neural network ...  \n",
              "1   multi view learning improves unsupervised sen...  \n",
              "2   we show how discrete objects can be learnt in...  \n",
              "3   a large scale dataset for training attention ...  \n",
              "4   we proposed a time efficient defense method a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80c55cae-2565-494d-bfac-c3b7153659c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>incremental class learning involves sequentia...</td>\n",
              "      <td>fearnet is a memory efficient neural network ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>multi view learning can provide self supervis...</td>\n",
              "      <td>multi view learning improves unsupervised sen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we show how discrete objects can be learnt in...</td>\n",
              "      <td>we show how discrete objects can be learnt in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>most recent gains in visual recognition have ...</td>\n",
              "      <td>a large scale dataset for training attention ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in recent years deep neural networks have dem...</td>\n",
              "      <td>we proposed a time efficient defense method a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80c55cae-2565-494d-bfac-c3b7153659c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80c55cae-2565-494d-bfac-c3b7153659c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80c55cae-2565-494d-bfac-c3b7153659c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b61ff81-c71d-401e-ab54-13850aab4b38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b61ff81-c71d-401e-ab54-13850aab4b38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b61ff81-c71d-401e-ab54-13850aab4b38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dftest",
              "summary": "{\n  \"name\": \"dftest\",\n  \"rows\": 618,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \" deep reinforcement learning drl algorithms have demonstrated progress in learning to find a goal in challenging environments as the title of the paper by mirowski et al suggests one might assume that drl based algorithms are able to learn to navigate and are thus ready to replace classical mapping and path planning algorithms at least in simulated environments yet from experiments and analysis in this earlier work it is not clear what strategies are used by these algorithms in navigating the mazes and finding the goal in this paper we pose and study this underlying question are drl algorithms doing some form of mapping and or path planning our experiments show that the algorithms are not memorizing the maps of mazes at the testing stage but rather at the training stage hence the drl algorithms fall short of qualifying as mapping or path planning algorithms with any reasonable definition of mapping we extend the experiments in mirowski et al by separating the set of training and testing maps and by a more ablative coverage of the space of experiments our systematic experiments show that the navac d d l algorithm when trained and tested on the same maps is able to choose the shorter paths to the goal however when tested on unseen maps the algorithm utilizes a wall following strategy to find the goal without doing any mapping or path planning navigation remains a fundamental problem in mobile robotics and artificial intelligence bid bid the problem is classically addressed by separating the task of navigation into two steps exploration and exploitation in the exploration stage the environment is represented as some kind of map in the exploitation stage the map is used to plan a path to a given destination based on some optimality criterion this classical approach has been quite successful in navigation using a variety of sensors however navigation in general unstructured environments especially with texture less bid transparent and reflective surfaces bid remains a challenge recently end to end navigation methods which attempt to solve the navigation problem without breaking it down into separate parts of mapping and path planning have gained traction with the recent advances in deep reinforcement learning drl these end to end navigation methods such as bid bid bid bid forego decisions about the details that are required in the intermediate step of mapping the potential for simpler yet more capable methods is rich for example the resulting trained agents can potentially optimize the amount of map information required for navigation tasks one such algorithm by bid has shown promise in exploring and finding the goal efficiently within complex environments notably this is done using only monocular first person views despite such potential advances drl based navigation remains a relatively unexplored field with its own limitations the black box nature of these methods make them difficult to study and the patterns captured by the methods are not well understood recent work analyzing neural networks has shown that deep learning based object detection methods can be easily fooled by introducing noise that is imperceptible to humans bid this level of sensitivity motivates why it is particularly important to analyze drl methods across a wide variety of experiments we need to understand their strengths and limitations figure snapshots of the path taken by the agent while evaluating the model trained on the same random map with random goal and random spawn the first row shows the top view of the robot moving through the maze with the goal location marked orange the agent marked black and the agent s orientation marked red the second row shows the first person view which besides reward is the only input available to the agent and the top view is available only for human analysis in this work we develop a better understanding of recent drl based methods in particular we thoroughly explore and analyze the state of the art bid methods across hundreds of maps with increasing difficulty levels we set up the environment as a randomly generated map as shown in fig with an agent and a goal the agent is provided only with the first person view and is tasked to find the goal as many times as possible within a fixed amount of time re spawning its location each time it reaches the goal we train and evaluate the algorithms with increasing difficulty in the easiest stage we keep the goal location spawn location and map constant over the training and testing we call this set up static goal static spawn and static map to increase the difficulty we incrementally randomize the spawn locations goal locations and map structures until all three are random we discuss the design of experiments in section in more detail bid do train and test their algorithms with randomized goals and spawns and show that their algorithm is able to exploit the knowledge of the goal location at evaluation time to maximize reward however following training and testing on constant map structures this state ofthe art result is shown to be successful on only one map which brings into question the repeatability of the results it is also unclear whether these results generalize to unseen maps although disjoint training and testing sets are standard practice in machine learning to the best of our knowledge we are the first to evaluate any drl based navigation method on maps with unseen structures we expand on the analysis in bid to address its limitations and ask whether drl based algorithms such as navac d d l perform any mapping followed by shortest path planning our experiments show no evidence of mapping in cases where algorithms are evaluated on unseen maps and no evidence of optimal path planning even when the map is constant and only the goal is randomized to better understand navigation we compute attention maps for models to show which portions of the input image are being used we find that the models discard most of the image information focusing attention on a small band in the middle of the image except around junctions in which case the attention is distributed evenly throughout the image these findings result from training and testing on multiple maps that were randomly selected from a set of randomly generated maps we provide experimental results on ten randomly selected maps and a testing set of unseen maps to ensure results are independent of map choice we will make our code and data available following the blind review process in this work we comprehensively evaluate navac d d l bid a drl based navigation algorithms through systematic set of experiments that are repeated over multiple randomly chosen maps our experiments show that drl based navigation models are able to perform some degree of path planning and mapping when trained and tested on the same map even when spawn locations and goal locations are randomized however the large variation in the evaluation metrics show that how such behaviour is not consistent across episodes we also train and test these methods on disjoint set of maps and show that such trained models fail to perform any form of path planning or mapping in unseen environments in this work we begin by asking do drl based navigation algorithms really learn to navigate our results answer this question negatively at best we can say that drl based algorithms learn to navigate in the exact same environment rather than general technique of navigation which is what classical mapping and path planning provide we hope that the systematic approach to the experiments in this work serve as a benchmark for future drl based navigation methods \",\n          \" we study discrete time dynamical systems governed by the state equation h_ t \\u03d5 ah_t bu_t here a b are weight matrices \\u03d5 is an activation function and u_t is the input data this relation is the backbone of recurrent neural networks e g lstms which have broad applications in sequential learning tasks we utilize stochastic gradient descent to learn the weight matrices from a finite input state trajectory u_t h_t _ t n we prove that sgd estimate linearly converges to the ground truth weights while using near optimal sample size our results apply to increasing activations whose derivatives are bounded away from zero the analysis is based on i an sgd convergence result with nonlinear activations and ii careful statistical characterization of the state vector numerical experiments verify the fast convergence of sgd on relu and leaky relu in consistence with our theory a wide range of problems involve sequential data with a natural temporal ordering examples include natural language processing time series prediction system identification and control design among others state of the art algorithms for sequential problems often stem from dynamical systems theory and are tailored to learn from temporally dependent data linear models and algorithms such as kalman filter pid controller and linear dynamical systems have a long history and are utilized in control theory since s with great success brown et al ho kalman \\u00e5str\\u00f6m h\\u00e4gglund more recently nonlinear models such as recurrent neural networks rnn found applications in complex tasks such as machine translation and speech recognition bahdanau et al graves et al hochreiter schmidhuber unlike feedforward neural networks rnns are dynamical systems that use their internal state to process inputs the goal of this work is to shed light on the inner workings of rnns from a theoretical point of view in particular we focus on the rnn state equation which is characterized by a nonlinear activation function \\u03c6 state weight matrix a and input weight matrix b as follows h t \\u03c6 ah t bu t here h t is the state vector and u t is the input data at timestamp t this equation is the source of dynamic behavior of rnns and distinguishes rnn from feedforward networks the weight matrices a and b govern the dynamics of the state equation and are inferred from data we will explore the statistical and computational efficiency of stochastic gradient descent sgd for learning these weight matrices contributions suppose we are given a finite trajectory of input state pairs u t h t n t generated from the state equation we consider a least squares regression obtained from n equations with inputs u t h t n t and outputs h t n t for a class of activation functions including leaky relu and for stable systems we show that sgd linearly converges to the ground truth weight matrices while requiring near optimal trajectory length n in particular the required sample size is o n p where n and p are the dimensions of the state and input vectors respectively the results are extended to unstable systems when the samples are collected from multiple independent rnn trajectories rather than a single trajectory our theory applies to increasing activation functions whose derivatives are bounded away from zero which includes leaky relu and gaussian input data numerical experiments on relu and leaky relu corroborate our theory and demonstrate that sgd converges faster as the activation slope increases to obtain our results we i characterize the statistical properties of the state vector e g well conditioned covariance and ii derive a novel sgd convergence result with nonlinear activations which may be of independent interest as a whole this paper provides a step towards foundational understanding of rnn training via sgd this work showed that sgd can learn the nonlinear dynamical system which is characterized by weight matrices and an activation function this problem is of interest for recurrent neural networks as well as nonlinear system identification we showed that efficient learning is possible with optimal sample complexity and good computational performance our results apply to strictly increasing activations such as leaky relu we empirically showed that leaky relu converges faster than relu and requires less samples in consistence with our theory we list a few unanswered problems that would provide further insights into recurrent neural networks covariance of the state vector our results depend on the covariance of the state vector and requires it to be positive definite one might be able to improve the current bounds on the condition number and relax the assumptions on the activation function deriving similar performance bounds for relu is particularly interesting hidden state for rnns the state vector is hidden and is observed through an additional equation which further complicates the optimization landscape even for linear dynamical systems learning the a b c d system is a non trivial task ho kalman hardt et al what can be said when we add the nonlinear activations classification task in this work we used normally distributed input and least squares regression for our theoretical guarantees more realistic input distributions might provide better insight into contemporary problems such as natural language processing where the goal is closer to classification e g finding the best translation from another language \",\n          \" most state of the art neural machine translation systems despite being different n in architectural skeletons e g recurrence convolutional share an indispensable n feature the attention however most existing attention methods are token based n and ignore the importance of phrasal alignments the key ingredient for the success n of phrase based statistical machine translation in this paper we propose n novel phrase based attention methods to model n grams of tokens as attention n entities we incorporate our phrase based attentions into the recently proposed n transformer network and demonstrate that our approach yields improvements of n bleu for english to german and bleu for german to english translation n tasks and and bleu points in english to russian and russian to english translation tasks n on wmt newstest using wmt training data n neural machine translation nmt has established breakthroughs in many different translation tasks and has quickly become the standard approach to machine translation nmt offers a simple encoder decoder architecture that is trained end to end most nmt models except a few like bid and bid possess attention mechanisms to perform alignments of the target tokens to the source tokens the attention module plays a role analogous to the word alignment model in statistical machine translation or smt bid in fact the transformer network introduced recently by bid achieves state of the art performance in both speed and bleu scores bid by using only attention modules on the other hand phrasal interpretation is an important aspect for many language processing tasks and forms the basis of phrase based machine translation bid phrasal alignments bid can model one to one one to many many to one and many to many relations between source and target tokens and use local context for translation they are also robust to non compositional phrases despite the advantages the concept of phrasal attentions has largely been neglected in nmt as most nmt models generate translations token by token autoregressively and use the token based attention method which is order invariant therefore the intuition of phrase based translation is vague in existing nmt systems that solely depend on the underlying neural architectures recurrent convolutional or self attention to incorporate contextual information however the information aggregation strategies employed by the underlying neural architectures provide context relevant clues only to represent the current token and do not explicitly model phrasal alignments we argue that having an explicit inductive bias for phrases and phrasal alignments is necessary for nmt to exploit the strong correlation between source and target phrases in this paper we propose phrase based attention methods for phrase level alignments in nmt specifically we propose two novel phrase based attentions namely convkv and queryk designed to assign attention scores directly to phrases in the source and compute phrase level attention vector for the target we also introduce three new attention structures which apply these methods to conduct phrasal alignments our homogeneous and heterogeneous attention structures perform token to token and token to phrase mappings while the interleaved heterogeneous attention structure models all token to token token to phrase phrase to token and phrase to phrase alignments to show the effectiveness of our approach we apply our phrase based attention methods to all multi head attention layers of the transformer our experiments on wmt translation tasks show improvements of up to and bleu points for english to german and german to english respectively and up to and bleu points for english to russian and russian to english respectively compared to the baseline transformer network trained in identical settings \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 618,\n        \"samples\": [\n          \" we quantitatively and qualitatively evaluate deep reinforcement learning based navigation methods under a variety of conditions to answer the question of how close they are to replacing classical path planners and mapping algorithms evaluate a deep rl based model on training mazes by measuring repeated latency to goal and comparison to shortest route \",\n          \" we study the state equation of a recurrent neural network we show that sgd can efficiently learn the unknown dynamics from few input output observations under proper assumptions the paper studies discrete time dynamical systems with a non linear state equation proving that running sgd on a fixed length trajectory gives logarithmic convergence this work considers the problem of learning a non linear dynamical system in which the output equals the state nthis paper studies the ability of sgd to learn dynamics of a linear system and non linear activation \",\n          \" phrase based attention mechanisms to assign attention on phrases achieving token to phrase phrase to token phrase to phrase attention alignments in addition to existing token to token attentions paper presents an attention mechanism that computes a weighted sum over not only single tokens but ngrams phrases \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u29GfCKETgbQ",
        "outputId": "0e6de0ad-8b3b-44b5-827d-7235daf9c564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 618 entries, 0 to 617\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    618 non-null    object\n",
            " 1   target  618 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Validation, Test Spliting"
      ],
      "metadata": {
        "id": "zF9lKifNdX5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df\n",
        "val_df = dfval\n",
        "test_df = dftest\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8qi_7dpcSwP",
        "outputId": "55900247-2695-476f-affc-99e2402105ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1992, Validation: 619, Test: 618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Dataset to HuggingFace"
      ],
      "metadata": {
        "id": "fbmxzUPsdfaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SummarizationDataset(Dataset): # class Cleansing yang final\n",
        "#     def __init__(self, dataframe, tokenizer, max_input_len=512, max_output_len=128):\n",
        "#         self.data = dataframe\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_input_len = max_input_len\n",
        "#         self.max_output_len = max_output_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         row = self.data.iloc[idx]\n",
        "#         #source = row[\"text\"]\n",
        "#         source = \"summarize: \" + \" \".join(row[\"text\"])\n",
        "#         target = row[\"target\"]\n",
        "\n",
        "#         source_encodings = self.tokenizer(\n",
        "#             source,\n",
        "#             max_length=self.max_input_len,\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "#         target_encodings = self.tokenizer(\n",
        "#             target,\n",
        "#             max_length=self.max_output_len,\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             \"input_ids\": source_encodings[\"input_ids\"].squeeze(),\n",
        "#             \"attention_mask\": source_encodings[\"attention_mask\"].squeeze(),\n",
        "#             \"labels\": target_encodings[\"input_ids\"].squeeze(),\n",
        "#         }"
      ],
      "metadata": {
        "id": "tGWA2uEPcaeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# class SCITldrDataset(Dataset): # class buat NonCleansing yang final\n",
        "#     def __init__(self, dataset, tokenizer, max_input_len=512, max_output_len=128):\n",
        "#         self.dataset = dataset  # Save the dataset object directly\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_input_len = max_input_len\n",
        "#         self.max_output_len = max_output_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.dataset)  # Use the length of the dataset\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         # Access the data entry using .iloc to ensure integer-based indexing\n",
        "#         item = self.dataset.iloc[idx]\n",
        "#         # Join the list of strings in 'source' into a single string\n",
        "#         input_text = \"summarize: \" + \" \".join(item[\"source\"])\n",
        "#         target_text = item[\"target\"]\n",
        "\n",
        "#         # Tokenize input and output\n",
        "#         inputs = self.tokenizer(\n",
        "#             input_text,\n",
        "#             max_length=self.max_input_len,\n",
        "#             truncation=True,\n",
        "#             padding=\"max_length\",\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "#         targets = self.tokenizer(\n",
        "#             target_text,\n",
        "#             max_length=self.max_output_len,\n",
        "#             truncation=True,\n",
        "#             padding=\"max_length\",\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "#             \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "#             \"labels\": targets[\"input_ids\"].squeeze(),\n",
        "#         }"
      ],
      "metadata": {
        "id": "eCPMwY7G--hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummarizationDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_input_len=128, max_output_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_output_len = max_output_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        # source = row[\"clean_text\"]\n",
        "        source = \"summarize: \" + row[\"text\"] # correct prefix\n",
        "        target = row[\"target\"]\n",
        "\n",
        "        source_encodings = self.tokenizer(\n",
        "            source,\n",
        "            max_length=self.max_input_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target_encodings = self.tokenizer(\n",
        "            target,\n",
        "            max_length=self.max_output_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source_encodings[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": source_encodings[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target_encodings[\"input_ids\"].squeeze(),\n",
        "        }"
      ],
      "metadata": {
        "id": "6vj6vXmiWFTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Model"
      ],
      "metadata": {
        "id": "J50Rlasfdlxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert2bert\"  # Using a BERT-to-BERT EncoderDecoder model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Model moved to {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ec97fe1d9da4c0ebb161ecf68d85dce",
            "d7498f33753d4e9ea768b0f7ed78f2b2",
            "fb860e5f3a314051abadb2403965ab6b",
            "82c9060fed404ecb941499bfc0764816",
            "ad5bf1338e914d0c8f4455d5294a99a8",
            "0c1bb0f5b0d0480ab2984b6b2b14ea9b",
            "3f9af5fb8537417f9dbd12d0023f2a0e",
            "fd0120681df84e9bb92673feb5b8633c",
            "8801b7dceb894763bbf1b6bde41e4086",
            "e843ca6ed8774fea957b6c79dc49da8b",
            "cda535cb74964608834ed733b991bcb6",
            "7c59b22bffcc49a2881d6e4ad018e004",
            "6582095c5f7c45d0b5d5317474626756",
            "e6ac22695c4c4261abfa3c075d94755a",
            "1d20887ea9264860a3c449271162acf9",
            "88379bad5dc1401ca93fc597e52d1a12",
            "0d131b8115c34a18a20f84c0586ee45d",
            "bcbf0523996d4d5e82d7fe39130ad380",
            "3c32da57ca844c879916e4379e9e7339",
            "f345462dbec143a3a825b7d20bb2cc41",
            "f489e4a5118c44f7ac48c0c497aa0afb",
            "f8021844a97242f4b82d5c13bf012cd6",
            "bdfbb0cb2b5c4c46ab289066b2b93c32",
            "0731eb21d7b34f7da1afc0021db971ed",
            "17160a9a88f14f4abdac11b839509aba",
            "66f11d3cd3f749d08bfd84973f21c464",
            "981802bcb4124613b7f17ce14c2d1eb8",
            "369bcb615a984a609405bf801646d792",
            "cb94e25652ef439284da5f61132b2cc2",
            "9fc8620a7aae41b6aa735ba2ec80be72",
            "efd71f5e108b44418ef6465e27b27a17",
            "12bcf3bf63f642e3b3280c72ecb4994e",
            "359812cea9ae47b79ea20e329d9d9fd9",
            "8bd984f1cd244e7d9f87f0e8a5513a9b",
            "d46ef578468e40b59024804140c588e3",
            "d35d38315cbd423fbdb60099235ffc38",
            "b0a6bd45e97a4d4b963bfadad67d7ce5",
            "35889c4b6960400b911ba7c26172b35b",
            "305c81f5a4c64f84a1d358a6573ff5a3",
            "db71fbf191794b0fa74ddbf150830dc7",
            "9c2278c5c40b491d8a14d5ce948889eb",
            "5bebcf0295304702a4d05a40b2c99777",
            "8d1b4ff7796046c7960ebb637be6effa",
            "310c6d00df044fa5bd43fdb2ea15ec0d",
            "0894ba063e0f4bedace1c5015538f719",
            "fa8a28736526445d9b1ace795c0e1f4b",
            "df422195dd2042d19f5336dad054f5d9",
            "a7e1bcd67ab44be58787721224681376",
            "f44e2f51817b469c95940e9ab4528d41",
            "28c0482c22754035a34ad74836001aa2",
            "67ed46614f2247248f09e21f9a209a41",
            "984e4a0a5e514a33a7dda97e350dc38f",
            "778ec912bc21461b8dc81c8cb9ae25f9",
            "af99afbdb90743eda4dcd1e15377495b",
            "68662272a8424d839c64890869d94725",
            "39cc850760764e1190a9471ff68138d6",
            "045358e04bd04001a1ca32e5d58e8037",
            "3eb5989448c04a688af1456f1355ac9a",
            "f7405feae0be48dfa2324a228d8d318e",
            "4873d0984b66455c8c5561179fbd180f",
            "5d96374cd0d741d1b26fbfaa9df95c38",
            "07147aeeff33445c940848d4ce01e8f4",
            "e591241f9fa84571a66bfbc29e77c3a8",
            "ff8244a4718749a9a5b4059c2e6da091",
            "37de6992f8b54fe1bd1e1ce86a5bcd00",
            "f061b0b124df4140bf82e7b0c951c2f5"
          ]
        },
        "id": "Wbt2SGcoccf-",
        "outputId": "eeaf0fb5-6a24-4adb-9cdd-7bb1495b865f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ec97fe1d9da4c0ebb161ecf68d85dce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c59b22bffcc49a2881d6e4ad018e004"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdfbb0cb2b5c4c46ab289066b2b93c32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bd984f1cd244e7d9f87f0e8a5513a9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0894ba063e0f4bedace1c5015538f719"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39cc850760764e1190a9471ff68138d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"return_dict\": false,\n",
            "  \"transformers_version\": \"4.47.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": true,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"return_dict\": false,\n",
            "  \"transformers_version\": \"4.47.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model moved to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets\n",
        "train_dataset = SummarizationDataset(train_df, tokenizer) # pake yang cleansing karena nama collumnnya beda\n",
        "val_dataset = SummarizationDataset(val_df, tokenizer)\n",
        "test_dataset = SummarizationDataset(test_df, tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "imRYwbBTcfUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Arc"
      ],
      "metadata": {
        "id": "65rIjfBAdrVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "epochs = 10  # Maximum epochs\n",
        "patience = 3  # Early stopping patience\n",
        "best_val_loss = float(\"inf\")\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print progress\n",
        "        if (step + 1) % 10 == 0:\n",
        "            print(f\"Step {step + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels,\n",
        "            )\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(\"Best model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJoZgy2Kch_S",
        "outputId": "5e515d79-6f84-45c3-fa56-2317a6c8a82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10/249, Loss: 4.3000\n",
            "Step 20/249, Loss: 2.0002\n",
            "Step 30/249, Loss: 1.4845\n",
            "Step 40/249, Loss: 1.0588\n",
            "Step 50/249, Loss: 1.0291\n",
            "Step 60/249, Loss: 0.4639\n",
            "Step 70/249, Loss: 0.7273\n",
            "Step 80/249, Loss: 0.7514\n",
            "Step 90/249, Loss: 0.9598\n",
            "Step 100/249, Loss: 0.7461\n",
            "Step 110/249, Loss: 0.8104\n",
            "Step 120/249, Loss: 0.6681\n",
            "Step 130/249, Loss: 0.6408\n",
            "Step 140/249, Loss: 0.6672\n",
            "Step 150/249, Loss: 0.8291\n",
            "Step 160/249, Loss: 0.5806\n",
            "Step 170/249, Loss: 0.7391\n",
            "Step 180/249, Loss: 0.7406\n",
            "Step 190/249, Loss: 0.8947\n",
            "Step 200/249, Loss: 0.8613\n",
            "Step 210/249, Loss: 0.6466\n",
            "Step 220/249, Loss: 0.7393\n",
            "Step 230/249, Loss: 0.7381\n",
            "Step 240/249, Loss: 0.7149\n",
            "Epoch 1 Training Loss: 1.1607\n",
            "Epoch 1 Validation Loss: 2.0244\n",
            "Best model saved.\n",
            "Epoch 2/10\n",
            "Step 10/249, Loss: 0.5087\n",
            "Step 20/249, Loss: 0.4747\n",
            "Step 30/249, Loss: 0.4941\n",
            "Step 40/249, Loss: 0.6409\n",
            "Step 50/249, Loss: 0.7503\n",
            "Step 60/249, Loss: 0.6333\n",
            "Step 70/249, Loss: 0.6380\n",
            "Step 80/249, Loss: 0.4229\n",
            "Step 90/249, Loss: 0.7055\n",
            "Step 100/249, Loss: 0.5384\n",
            "Step 110/249, Loss: 0.8164\n",
            "Step 120/249, Loss: 0.4752\n",
            "Step 130/249, Loss: 0.7138\n",
            "Step 140/249, Loss: 0.7269\n",
            "Step 150/249, Loss: 0.6015\n",
            "Step 160/249, Loss: 0.5829\n",
            "Step 170/249, Loss: 0.4798\n",
            "Step 180/249, Loss: 0.5762\n",
            "Step 190/249, Loss: 0.5089\n",
            "Step 200/249, Loss: 0.6167\n",
            "Step 210/249, Loss: 0.4906\n",
            "Step 220/249, Loss: 0.9202\n",
            "Step 230/249, Loss: 0.3601\n",
            "Step 240/249, Loss: 0.7078\n",
            "Epoch 2 Training Loss: 0.5929\n",
            "Epoch 2 Validation Loss: 1.9853\n",
            "Best model saved.\n",
            "Epoch 3/10\n",
            "Step 10/249, Loss: 0.4902\n",
            "Step 20/249, Loss: 0.5381\n",
            "Step 30/249, Loss: 0.4801\n",
            "Step 40/249, Loss: 0.4894\n",
            "Step 50/249, Loss: 0.5074\n",
            "Step 60/249, Loss: 0.6546\n",
            "Step 70/249, Loss: 0.3144\n",
            "Step 80/249, Loss: 0.4931\n",
            "Step 90/249, Loss: 0.5418\n",
            "Step 100/249, Loss: 0.5037\n",
            "Step 110/249, Loss: 0.4928\n",
            "Step 120/249, Loss: 0.4869\n",
            "Step 130/249, Loss: 0.5234\n",
            "Step 140/249, Loss: 0.5029\n",
            "Step 150/249, Loss: 0.5057\n",
            "Step 160/249, Loss: 0.4009\n",
            "Step 170/249, Loss: 0.6742\n",
            "Step 180/249, Loss: 0.5516\n",
            "Step 190/249, Loss: 0.5710\n",
            "Step 200/249, Loss: 0.4891\n",
            "Step 210/249, Loss: 0.6746\n",
            "Step 220/249, Loss: 0.6965\n",
            "Step 230/249, Loss: 0.5791\n",
            "Step 240/249, Loss: 0.3737\n",
            "Epoch 3 Training Loss: 0.4937\n",
            "Epoch 3 Validation Loss: 2.0285\n",
            "No improvement. Patience: 1/3\n",
            "Epoch 4/10\n",
            "Step 10/249, Loss: 0.4581\n",
            "Step 20/249, Loss: 0.4402\n",
            "Step 30/249, Loss: 0.4170\n",
            "Step 40/249, Loss: 0.3417\n",
            "Step 50/249, Loss: 0.4439\n",
            "Step 60/249, Loss: 0.3051\n",
            "Step 70/249, Loss: 0.3965\n",
            "Step 80/249, Loss: 0.2978\n",
            "Step 90/249, Loss: 0.3110\n",
            "Step 100/249, Loss: 0.3800\n",
            "Step 110/249, Loss: 0.3524\n",
            "Step 120/249, Loss: 0.3984\n",
            "Step 130/249, Loss: 0.3792\n",
            "Step 140/249, Loss: 0.3176\n",
            "Step 150/249, Loss: 0.4683\n",
            "Step 160/249, Loss: 0.4323\n",
            "Step 170/249, Loss: 0.4679\n",
            "Step 180/249, Loss: 0.3982\n",
            "Step 190/249, Loss: 0.3421\n",
            "Step 200/249, Loss: 0.4755\n",
            "Step 210/249, Loss: 0.3002\n",
            "Step 220/249, Loss: 0.4459\n",
            "Step 230/249, Loss: 0.3982\n",
            "Step 240/249, Loss: 0.3702\n",
            "Epoch 4 Training Loss: 0.4023\n",
            "Epoch 4 Validation Loss: 2.1388\n",
            "No improvement. Patience: 2/3\n",
            "Epoch 5/10\n",
            "Step 10/249, Loss: 0.2837\n",
            "Step 20/249, Loss: 0.2800\n",
            "Step 30/249, Loss: 0.3839\n",
            "Step 40/249, Loss: 0.3293\n",
            "Step 50/249, Loss: 0.2866\n",
            "Step 60/249, Loss: 0.1810\n",
            "Step 70/249, Loss: 0.3097\n",
            "Step 80/249, Loss: 0.2931\n",
            "Step 90/249, Loss: 0.4099\n",
            "Step 100/249, Loss: 0.3367\n",
            "Step 110/249, Loss: 0.3062\n",
            "Step 120/249, Loss: 0.2699\n",
            "Step 130/249, Loss: 0.3324\n",
            "Step 140/249, Loss: 0.3918\n",
            "Step 150/249, Loss: 0.2577\n",
            "Step 160/249, Loss: 0.3380\n",
            "Step 170/249, Loss: 0.3491\n",
            "Step 180/249, Loss: 0.4267\n",
            "Step 190/249, Loss: 0.3064\n",
            "Step 200/249, Loss: 0.3772\n",
            "Step 210/249, Loss: 0.3830\n",
            "Step 220/249, Loss: 0.2887\n",
            "Step 230/249, Loss: 0.2622\n",
            "Step 240/249, Loss: 0.3361\n",
            "Epoch 5 Training Loss: 0.3175\n",
            "Epoch 5 Validation Loss: 2.2193\n",
            "No improvement. Patience: 3/3\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Tournament Arc"
      ],
      "metadata": {
        "id": "RkGAldEDdvyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150)\n",
        "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        decoded_refs = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
        "\n",
        "        predictions.extend(decoded_preds)\n",
        "        references.extend(decoded_refs)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "rouge1, rouge2, rougeL = 0, 0, 0\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1 += scores[\"rouge1\"].fmeasure\n",
        "    rouge2 += scores[\"rouge2\"].fmeasure\n",
        "    rougeL += scores[\"rougeL\"].fmeasure\n",
        "\n",
        "n = len(predictions)\n",
        "print(f\"ROUGE-1: {rouge1 / n:.4f}\")\n",
        "print(f\"ROUGE-2: {rouge2 / n:.4f}\")\n",
        "print(f\"ROUGE-L: {rougeL / n:.4f}\")\n"
      ],
      "metadata": {
        "id": "RrXyG4tWcjNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ed94e2-7dc4-4f31-d2c7-ec168e1ad0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-5a2e5aa9e4ab>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pt\"))\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1: 0.3868\n",
            "ROUGE-2: 0.1215\n",
            "ROUGE-L: 0.2435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ROUGE-1: {rouge1 * 100 / n:.4f} %\")\n",
        "print(f\"ROUGE-2: {rouge2 * 100 / n:.4f} %\")\n",
        "print(f\"ROUGE-L: {rougeL * 100 / n:.4f} %\")"
      ],
      "metadata": {
        "id": "_tN99QnPcl23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346fda13-a490-4915-d632-e85eb9624e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1: 38.6842 %\n",
            "ROUGE-2: 12.1461 %\n",
            "ROUGE-L: 24.3546 %\n"
          ]
        }
      ]
    }
  ]
}